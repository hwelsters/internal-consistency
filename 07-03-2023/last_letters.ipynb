{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import libraries**\n",
    "`lab_v2` is a library containing methods that are often used throughout our GPT experiments.  \n",
    "This library can be found at the following url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import Counter\n",
    "from enum import Enum\n",
    "\n",
    "import pandas\n",
    "\n",
    "from lab_v2 import gpt_eval\n",
    "from lab_v2 import io\n",
    "from lab_v2 import stats\n",
    "from lab_v2.xlsx_creation import XlsxWorkbook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Constants**\n",
    "Specify a few constants to make the notebook easier to configure in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Enum):\n",
    "    LAST_LETTERS = 0\n",
    "    CSQA = 1\n",
    "\n",
    "DATASET = Dataset.LAST_LETTERS\n",
    "QUESTION_SET_FILE_PATH = 'data/question-set/last_letters.jsonl'\n",
    "RESPONSE_FILE_PATH = 'data/responses/last_letters/sample_0.jsonl'\n",
    "OUT_FILE_PATH = 'out/Last Letters.xlsx'\n",
    "NUM_SAMPLES = 10\n",
    "\n",
    "# DATASET = Dataset.CSQA\n",
    "# QUESTION_SET_FILE_PATH = 'data/question-set/csqa.jsonl'\n",
    "# RESPONSE_FILE_PATH = 'data/responses/csqa/sample_0.jsonl'\n",
    "# OUT_FILE_PATH = 'out/CSQA.xlsx'\n",
    "# NUM_SAMPLES = 10\n",
    "\n",
    "if DATASET == Dataset.LAST_LETTERS:\n",
    "    QUESTION_SET_INDEX_NAME = 'iIndex'\n",
    "    QUESTION_SET_ANSWER_NAME = 'answer'\n",
    "    RESPONSE_INDEX_NAME = 'question_id'\n",
    "    RESPONSE_SAMPLE_NAME = 'choices'\n",
    "    EXTRACT_RESPONSE = lambda response: response['message']['content']\n",
    "    ANSWER_EXTRACTION = gpt_eval.extract_last_letters\n",
    "    COMPARE_ANSWERS = lambda x, y: x == y\n",
    "if DATASET == Dataset.CSQA:\n",
    "    QUESTION_SET_INDEX_NAME = 'id'\n",
    "    QUESTION_SET_ANSWER_NAME = 'answerKey'\n",
    "    RESPONSE_INDEX_NAME = 'question_id'\n",
    "    RESPONSE_SAMPLE_NAME = 'choices'\n",
    "    EXTRACT_RESPONSE = lambda response: response['message']['content']\n",
    "    ANSWER_EXTRACTION = gpt_eval.extract_csqa\n",
    "    COMPARE_ANSWERS = lambda x, y: x.lower() == y.lower()\n",
    "\n",
    "\n",
    "\n",
    "RESPONSE_ANSWERS_NAME = 'answers'\n",
    "MAJORITY_ANSWER_NAME = 'majority_answer'\n",
    "MAJORITY_CORRECT_NAME = 'majority_correct'\n",
    "ENTROPY_COLUMN = 'shannon_entropy'\n",
    "GINI_IMPURITY_COLUMN = 'gini_impurity'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **File I/O**\n",
    "Specify a few functions that make it easier to read from files using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iIndex</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>rany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iIndex answer\n",
       "0       0   rany"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_set = io.read_file(QUESTION_SET_FILE_PATH)\n",
    "question_set = question_set[[QUESTION_SET_INDEX_NAME, QUESTION_SET_ANSWER_NAME]]\n",
    "display(len(question_set))\n",
    "question_set.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>choices</th>\n",
       "      <th>usage</th>\n",
       "      <th>question</th>\n",
       "      <th>n</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>chatcmpl-7XlFtWDh2tBIfBANVqU5WPrpi3cj6</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1688280829</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>[{'index': 0, 'message': {'role': 'assistant',...</td>\n",
       "      <td>{'prompt_tokens': 55, 'completion_tokens': 149...</td>\n",
       "      <td>At the end, say 'the answer is [put the concat...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id                                      id           object   \n",
       "0           31  chatcmpl-7XlFtWDh2tBIfBANVqU5WPrpi3cj6  chat.completion  \\\n",
       "\n",
       "      created          model   \n",
       "0  1688280829  gpt-3.5-turbo  \\\n",
       "\n",
       "                                             choices   \n",
       "0  [{'index': 0, 'message': {'role': 'assistant',...  \\\n",
       "\n",
       "                                               usage   \n",
       "0  {'prompt_tokens': 55, 'completion_tokens': 149...  \\\n",
       "\n",
       "                                            question   n  temperature  \n",
       "0  At the end, say 'the answer is [put the concat...  20          0.7  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = io.read_file(RESPONSE_FILE_PATH)\n",
    "display(len(responses))\n",
    "responses.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>choices</th>\n",
       "      <th>usage</th>\n",
       "      <th>question</th>\n",
       "      <th>n</th>\n",
       "      <th>temperature</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>chatcmpl-7XlFtWDh2tBIfBANVqU5WPrpi3cj6</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1688280829</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>[{'index': 0, 'message': {'role': 'assistant',...</td>\n",
       "      <td>{'prompt_tokens': 55, 'completion_tokens': 149...</td>\n",
       "      <td>At the end, say 'the answer is [put the concat...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>yral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 id           object   \n",
       "question_id                                                            \n",
       "31           chatcmpl-7XlFtWDh2tBIfBANVqU5WPrpi3cj6  chat.completion  \\\n",
       "\n",
       "                created          model   \n",
       "question_id                              \n",
       "31           1688280829  gpt-3.5-turbo  \\\n",
       "\n",
       "                                                       choices   \n",
       "question_id                                                      \n",
       "31           [{'index': 0, 'message': {'role': 'assistant',...  \\\n",
       "\n",
       "                                                         usage   \n",
       "question_id                                                      \n",
       "31           {'prompt_tokens': 55, 'completion_tokens': 149...  \\\n",
       "\n",
       "                                                      question   n   \n",
       "question_id                                                          \n",
       "31           At the end, say 'the answer is [put the concat...  20  \\\n",
       "\n",
       "             temperature answer  \n",
       "question_id                      \n",
       "31                   0.7   yral  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = responses.set_index(RESPONSE_INDEX_NAME).join(question_set.set_index(QUESTION_SET_INDEX_NAME))\n",
    "display(len(joined))\n",
    "joined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>choices</th>\n",
       "      <th>usage</th>\n",
       "      <th>question</th>\n",
       "      <th>n</th>\n",
       "      <th>temperature</th>\n",
       "      <th>answer</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>chatcmpl-7XlFtWDh2tBIfBANVqU5WPrpi3cj6</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1688280829</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>[{'index': 0, 'message': {'role': 'assistant',...</td>\n",
       "      <td>{'prompt_tokens': 55, 'completion_tokens': 149...</td>\n",
       "      <td>At the end, say 'the answer is [put the concat...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>yral</td>\n",
       "      <td>[yrela, yagl, dyal, yrela, yagl, yagl, yal, ya...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 id           object   \n",
       "question_id                                                            \n",
       "31           chatcmpl-7XlFtWDh2tBIfBANVqU5WPrpi3cj6  chat.completion  \\\n",
       "\n",
       "                created          model   \n",
       "question_id                              \n",
       "31           1688280829  gpt-3.5-turbo  \\\n",
       "\n",
       "                                                       choices   \n",
       "question_id                                                      \n",
       "31           [{'index': 0, 'message': {'role': 'assistant',...  \\\n",
       "\n",
       "                                                         usage   \n",
       "question_id                                                      \n",
       "31           {'prompt_tokens': 55, 'completion_tokens': 149...  \\\n",
       "\n",
       "                                                      question   n   \n",
       "question_id                                                          \n",
       "31           At the end, say 'the answer is [put the concat...  20  \\\n",
       "\n",
       "             temperature answer   \n",
       "question_id                       \n",
       "31                   0.7   yral  \\\n",
       "\n",
       "                                                       answers  \n",
       "question_id                                                     \n",
       "31           [yrela, yagl, dyal, yrela, yagl, yagl, yal, ya...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_answers(row, column):\n",
    "    answers = []\n",
    "    for index, element in enumerate(row[column]): \n",
    "        if index > NUM_SAMPLES: break\n",
    "        response = EXTRACT_RESPONSE(element)\n",
    "        answers.append(ANSWER_EXTRACTION(response))\n",
    "    row[RESPONSE_ANSWERS_NAME] = answers\n",
    "    return row\n",
    "\n",
    "joined = joined.apply(lambda row: extract_answers(row, RESPONSE_SAMPLE_NAME), axis=1)\n",
    "joined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>choices</th>\n",
       "      <th>usage</th>\n",
       "      <th>question</th>\n",
       "      <th>n</th>\n",
       "      <th>temperature</th>\n",
       "      <th>answer</th>\n",
       "      <th>answers</th>\n",
       "      <th>majority_answer</th>\n",
       "      <th>majority_correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>chatcmpl-7XlFtWDh2tBIfBANVqU5WPrpi3cj6</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1688280829</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>[{'index': 0, 'message': {'role': 'assistant',...</td>\n",
       "      <td>{'prompt_tokens': 55, 'completion_tokens': 149...</td>\n",
       "      <td>At the end, say 'the answer is [put the concat...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>yral</td>\n",
       "      <td>[yrela, yagl, dyal, yrela, yagl, yagl, yal, ya...</td>\n",
       "      <td>yagl</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 id           object   \n",
       "question_id                                                            \n",
       "31           chatcmpl-7XlFtWDh2tBIfBANVqU5WPrpi3cj6  chat.completion  \\\n",
       "\n",
       "                created          model   \n",
       "question_id                              \n",
       "31           1688280829  gpt-3.5-turbo  \\\n",
       "\n",
       "                                                       choices   \n",
       "question_id                                                      \n",
       "31           [{'index': 0, 'message': {'role': 'assistant',...  \\\n",
       "\n",
       "                                                         usage   \n",
       "question_id                                                      \n",
       "31           {'prompt_tokens': 55, 'completion_tokens': 149...  \\\n",
       "\n",
       "                                                      question   n   \n",
       "question_id                                                          \n",
       "31           At the end, say 'the answer is [put the concat...  20  \\\n",
       "\n",
       "             temperature answer   \n",
       "question_id                       \n",
       "31                   0.7   yral  \\\n",
       "\n",
       "                                                       answers   \n",
       "question_id                                                      \n",
       "31           [yrela, yagl, dyal, yrela, yagl, yagl, yal, ya...  \\\n",
       "\n",
       "            majority_answer  majority_correct  \n",
       "question_id                                    \n",
       "31                     yagl             False  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_majority(answers: List[str]):\n",
    "    counter = Counter(answers)\n",
    "    return counter.most_common()[0][0]\n",
    "joined[MAJORITY_ANSWER_NAME] = joined[RESPONSE_ANSWERS_NAME].apply(lambda row : get_majority(row))\n",
    "joined[MAJORITY_CORRECT_NAME] = joined.apply(lambda row : COMPARE_ANSWERS(row[MAJORITY_ANSWER_NAME], row[QUESTION_SET_ANSWER_NAME]), axis=1)\n",
    "joined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>choices</th>\n",
       "      <th>usage</th>\n",
       "      <th>question</th>\n",
       "      <th>n</th>\n",
       "      <th>temperature</th>\n",
       "      <th>answer</th>\n",
       "      <th>answers</th>\n",
       "      <th>majority_answer</th>\n",
       "      <th>majority_correct</th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>gini_impurity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>chatcmpl-7XlFtWDh2tBIfBANVqU5WPrpi3cj6</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1688280829</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>[{'index': 0, 'message': {'role': 'assistant',...</td>\n",
       "      <td>{'prompt_tokens': 55, 'completion_tokens': 149...</td>\n",
       "      <td>At the end, say 'the answer is [put the concat...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>yral</td>\n",
       "      <td>[yrela, yagl, dyal, yrela, yagl, yagl, yal, ya...</td>\n",
       "      <td>yagl</td>\n",
       "      <td>False</td>\n",
       "      <td>1.672625</td>\n",
       "      <td>0.793388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 id           object   \n",
       "question_id                                                            \n",
       "31           chatcmpl-7XlFtWDh2tBIfBANVqU5WPrpi3cj6  chat.completion  \\\n",
       "\n",
       "                created          model   \n",
       "question_id                              \n",
       "31           1688280829  gpt-3.5-turbo  \\\n",
       "\n",
       "                                                       choices   \n",
       "question_id                                                      \n",
       "31           [{'index': 0, 'message': {'role': 'assistant',...  \\\n",
       "\n",
       "                                                         usage   \n",
       "question_id                                                      \n",
       "31           {'prompt_tokens': 55, 'completion_tokens': 149...  \\\n",
       "\n",
       "                                                      question   n   \n",
       "question_id                                                          \n",
       "31           At the end, say 'the answer is [put the concat...  20  \\\n",
       "\n",
       "             temperature answer   \n",
       "question_id                       \n",
       "31                   0.7   yral  \\\n",
       "\n",
       "                                                       answers   \n",
       "question_id                                                      \n",
       "31           [yrela, yagl, dyal, yrela, yagl, yagl, yal, ya...  \\\n",
       "\n",
       "            majority_answer  majority_correct  shannon_entropy  gini_impurity  \n",
       "question_id                                                                    \n",
       "31                     yagl             False         1.672625       0.793388  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined[ENTROPY_COLUMN] = joined[RESPONSE_ANSWERS_NAME].apply(lambda row : stats.shannon_entropy(row))\n",
    "joined[GINI_IMPURITY_COLUMN] = joined[RESPONSE_ANSWERS_NAME].apply(lambda row : stats.gini_impurity(row))\n",
    "joined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chart(dataframe: pandas.DataFrame, x_axis: str, y_axis: str, filter):\n",
    "    ret = []\n",
    "    values = dataframe[x_axis].sort_values().unique().tolist()\n",
    "    for value in values:\n",
    "        filtered_entropy = dataframe[filter(dataframe[x_axis], value)]\n",
    "        filtered_wrong = filtered_entropy[~filtered_entropy[y_axis]]\n",
    "        \n",
    "        if len(filtered_entropy) == 0: break\n",
    "        ret.append({\n",
    "            x_axis: value, \n",
    "            'support': len(filtered_entropy), \n",
    "            'amount_wrong': len(filtered_wrong), \n",
    "            'probability_of_failure': len(filtered_wrong) / len(filtered_entropy)\n",
    "        })\n",
    "\n",
    "    return pandas.DataFrame(ret)\n",
    "\n",
    "def generate_geq(dataframe: pandas.DataFrame, x_axis: str, y_axis: str):\n",
    "    return generate_chart(dataframe, x_axis, y_axis, lambda dat, y: dat >= y)\n",
    "\n",
    "def generate_leq(dataframe: pandas.DataFrame, x_axis: str, y_axis: str):\n",
    "    return generate_chart(dataframe, x_axis, y_axis, lambda dat, y: dat <= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>support</th>\n",
       "      <th>amount_wrong</th>\n",
       "      <th>probability_of_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>1473</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shannon_entropy  support  amount_wrong  probability_of_failure\n",
       "0              0.0     3000          1473                   0.491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gini_impurity</th>\n",
       "      <th>support</th>\n",
       "      <th>amount_wrong</th>\n",
       "      <th>probability_of_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3000</td>\n",
       "      <td>1473</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gini_impurity  support  amount_wrong  probability_of_failure\n",
       "0            0.0     3000          1473                   0.491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entropy_geq = generate_geq(joined, ENTROPY_COLUMN, MAJORITY_CORRECT_NAME)\n",
    "gini_impurity_geq = generate_geq(joined, GINI_IMPURITY_COLUMN, MAJORITY_CORRECT_NAME)\n",
    "\n",
    "display(entropy_geq.head(1))\n",
    "display(gini_impurity_geq.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>support</th>\n",
       "      <th>amount_wrong</th>\n",
       "      <th>probability_of_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shannon_entropy  support  amount_wrong  probability_of_failure\n",
       "0              0.0       10             0                     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gini_impurity</th>\n",
       "      <th>support</th>\n",
       "      <th>amount_wrong</th>\n",
       "      <th>probability_of_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gini_impurity  support  amount_wrong  probability_of_failure\n",
       "0            0.0       10             0                     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entropy_leq = generate_leq(joined, ENTROPY_COLUMN, MAJORITY_CORRECT_NAME)\n",
    "gini_impurity_leq = generate_leq(joined, GINI_IMPURITY_COLUMN, MAJORITY_CORRECT_NAME)\n",
    "display(entropy_leq.head(1))\n",
    "display(gini_impurity_leq.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = XlsxWorkbook(OUT_FILE_PATH)\n",
    "entropy_geq_worksheet = workbook.add_sheet('Entropy_GEQ', entropy_geq)\n",
    "entropy_geq_worksheet.add_scatter_chart('Entropy vs Probability of failure (GEQ)', ENTROPY_COLUMN, 'probability_of_failure', 'H1')\n",
    "\n",
    "entropy_leq_worksheet = workbook.add_sheet('Entropy_LEQ', entropy_leq)\n",
    "entropy_leq_worksheet.add_scatter_chart('Entropy vs Probability of failure (LEQ)', ENTROPY_COLUMN, 'probability_of_failure', 'H1')\n",
    "\n",
    "entropy_leq_worksheet = workbook.add_sheet('Gini_Impurity_LEQ', gini_impurity_geq)\n",
    "entropy_leq_worksheet.add_scatter_chart('Gini Impurity vs Probability of failure (LEQ)', GINI_IMPURITY_COLUMN, 'probability_of_failure', 'H1')\n",
    "\n",
    "entropy_leq_worksheet = workbook.add_sheet('Gini_Impurity_GEQ', gini_impurity_geq)\n",
    "entropy_leq_worksheet.add_scatter_chart('Gini Impurity vs Probability of failure (GEQ)', GINI_IMPURITY_COLUMN, 'probability_of_failure', 'H1')\n",
    "\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
