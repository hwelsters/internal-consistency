{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import libraries**\n",
    "`lab_v2` is a library containing methods that are often used throughout our GPT experiments.  \n",
    "This library can be found at the following url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import Counter\n",
    "\n",
    "import pandas\n",
    "from lab_v2.gpt_eval.eval import Eval\n",
    "from lab_v2.io.pandas import PandasIO\n",
    "from lab_v2.statistics.entropy import ShannonEntropy\n",
    "from lab_v2.xlsx_creation.xlsx_creation import XlsxWorkbook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Constants**\n",
    "Specify a few constants to make the notebook easier to configure in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These must absolutely be changed from test to test\n",
    "QUESTION_SET_FILE_PATH = 'data/question-set/last_letters.jsonl'\n",
    "QUESTION_SET_INDEX_NAME = 'iIndex'\n",
    "QUESTION_SET_ANSWER_NAME = 'answer'\n",
    "\n",
    "RESPONSE_FILE_PATH = 'data/responses/last_letters/sample_0.jsonl'\n",
    "RESPONSE_INDEX_NAME = 'question_id'\n",
    "RESPONSE_SAMPLE_NAME = 'choices'\n",
    "\n",
    "EXTRACT_RESPONSE = lambda response: response['message']['content']\n",
    "ANSWER_EXTRACTION = Eval.extract_last_letters\n",
    "COMPARE_ANSWERS = lambda x, y: x == y\n",
    "\n",
    "OUT_FILE_PATH = 'out/Last Letters.xlsx'\n",
    "NUM_SAMPLES = 10\n",
    "\n",
    "\n",
    "# QUESTION_SET_FILE_PATH = 'data/question-set/csqa.jsonl'\n",
    "# QUESTION_SET_INDEX_NAME = 'id'\n",
    "# QUESTION_SET_ANSWER_NAME = 'answerKey'\n",
    "\n",
    "# RESPONSE_FILE_PATH = 'data/responses/csqa/sample_0.jsonl'\n",
    "# RESPONSE_INDEX_NAME = 'question_id'\n",
    "# RESPONSE_SAMPLE_NAME = 'choices'\n",
    "\n",
    "# EXTRACT_RESPONSE = lambda response: response['message']['content']\n",
    "# ANSWER_EXTRACTION = Eval.extract_csqa\n",
    "# COMPARE_ANSWERS = lambda x, y: x.lower() == y.lower()\n",
    "\n",
    "# OUT_FILE_PATH = 'out/CSQA.xlsx'\n",
    "# NUM_SAMPLES = 10\n",
    "\n",
    "# These are here just to make it easier\n",
    "RESPONSE_ANSWERS_NAME = 'answers'\n",
    "\n",
    "MAJORITY_ANSWER_NAME = 'majority_answer'\n",
    "MAJORITY_CORRECT_NAME = 'majority_correct'\n",
    "\n",
    "ENTROPY_COLUMN = 'shannon_entropy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **File I/O**\n",
    "Specify a few functions that make it easier to read from files using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9741"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answerKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>075e483d21c29a511267ef62bedc0461</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id answerKey\n",
       "0  075e483d21c29a511267ef62bedc0461         A"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_set = PandasIO.read_file(QUESTION_SET_FILE_PATH)\n",
    "question_set = question_set[[QUESTION_SET_INDEX_NAME, QUESTION_SET_ANSWER_NAME]]\n",
    "display(len(question_set))\n",
    "question_set.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9741"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>usage</th>\n",
       "      <th>choices</th>\n",
       "      <th>question</th>\n",
       "      <th>n</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ac0351d8649fb60af40c5638061a2e21</td>\n",
       "      <td>chatcmpl-7K6z3XYWOvPh7edXDkJhKGmQwlKek</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1685027761</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>{'prompt_tokens': 75, 'completion_tokens': 140...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "      <td>Answer A, B, C or D. At the end, say 'the answ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id                                      id   \n",
       "0  ac0351d8649fb60af40c5638061a2e21  chatcmpl-7K6z3XYWOvPh7edXDkJhKGmQwlKek  \\\n",
       "\n",
       "            object     created          model   \n",
       "0  chat.completion  1685027761  gpt-3.5-turbo  \\\n",
       "\n",
       "                                               usage   \n",
       "0  {'prompt_tokens': 75, 'completion_tokens': 140...  \\\n",
       "\n",
       "                                             choices   \n",
       "0  [{'message': {'role': 'assistant', 'content': ...  \\\n",
       "\n",
       "                                            question   n  temperature  \n",
       "0  Answer A, B, C or D. At the end, say 'the answ...  20          0.7  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = PandasIO.read_file(RESPONSE_FILE_PATH)\n",
    "display(len(responses))\n",
    "responses.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9741"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>usage</th>\n",
       "      <th>choices</th>\n",
       "      <th>question</th>\n",
       "      <th>n</th>\n",
       "      <th>temperature</th>\n",
       "      <th>answerKey</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ac0351d8649fb60af40c5638061a2e21</th>\n",
       "      <td>chatcmpl-7K6z3XYWOvPh7edXDkJhKGmQwlKek</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1685027761</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>{'prompt_tokens': 75, 'completion_tokens': 140...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "      <td>Answer A, B, C or D. At the end, say 'the answ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      id   \n",
       "question_id                                                                \n",
       "ac0351d8649fb60af40c5638061a2e21  chatcmpl-7K6z3XYWOvPh7edXDkJhKGmQwlKek  \\\n",
       "\n",
       "                                           object     created          model   \n",
       "question_id                                                                    \n",
       "ac0351d8649fb60af40c5638061a2e21  chat.completion  1685027761  gpt-3.5-turbo  \\\n",
       "\n",
       "                                                                              usage   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  {'prompt_tokens': 75, 'completion_tokens': 140...  \\\n",
       "\n",
       "                                                                            choices   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  [{'message': {'role': 'assistant', 'content': ...  \\\n",
       "\n",
       "                                                                           question   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  Answer A, B, C or D. At the end, say 'the answ...  \\\n",
       "\n",
       "                                   n  temperature answerKey  \n",
       "question_id                                                  \n",
       "ac0351d8649fb60af40c5638061a2e21  20          0.7         D  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = responses.set_index(RESPONSE_INDEX_NAME).join(question_set.set_index(QUESTION_SET_INDEX_NAME))\n",
    "display(len(joined))\n",
    "joined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>usage</th>\n",
       "      <th>choices</th>\n",
       "      <th>question</th>\n",
       "      <th>n</th>\n",
       "      <th>temperature</th>\n",
       "      <th>answerKey</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ac0351d8649fb60af40c5638061a2e21</th>\n",
       "      <td>chatcmpl-7K6z3XYWOvPh7edXDkJhKGmQwlKek</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1685027761</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>{'prompt_tokens': 75, 'completion_tokens': 140...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "      <td>Answer A, B, C or D. At the end, say 'the answ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>D</td>\n",
       "      <td>[d, d, d, d, d, d, d, d, d, d, d]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      id   \n",
       "question_id                                                                \n",
       "ac0351d8649fb60af40c5638061a2e21  chatcmpl-7K6z3XYWOvPh7edXDkJhKGmQwlKek  \\\n",
       "\n",
       "                                           object     created          model   \n",
       "question_id                                                                    \n",
       "ac0351d8649fb60af40c5638061a2e21  chat.completion  1685027761  gpt-3.5-turbo  \\\n",
       "\n",
       "                                                                              usage   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  {'prompt_tokens': 75, 'completion_tokens': 140...  \\\n",
       "\n",
       "                                                                            choices   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  [{'message': {'role': 'assistant', 'content': ...  \\\n",
       "\n",
       "                                                                           question   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  Answer A, B, C or D. At the end, say 'the answ...  \\\n",
       "\n",
       "                                   n  temperature answerKey   \n",
       "question_id                                                   \n",
       "ac0351d8649fb60af40c5638061a2e21  20          0.7         D  \\\n",
       "\n",
       "                                                            answers  \n",
       "question_id                                                          \n",
       "ac0351d8649fb60af40c5638061a2e21  [d, d, d, d, d, d, d, d, d, d, d]  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_answers(row, column):\n",
    "    answers = []\n",
    "    for index, element in enumerate(row[column]): \n",
    "        if index > NUM_SAMPLES: break\n",
    "        response = EXTRACT_RESPONSE(element)\n",
    "        answers.append(ANSWER_EXTRACTION(response))\n",
    "    row[RESPONSE_ANSWERS_NAME] = answers\n",
    "    return row\n",
    "\n",
    "joined = joined.apply(lambda row: extract_answers(row, RESPONSE_SAMPLE_NAME), axis=1)\n",
    "joined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>usage</th>\n",
       "      <th>choices</th>\n",
       "      <th>question</th>\n",
       "      <th>n</th>\n",
       "      <th>temperature</th>\n",
       "      <th>answerKey</th>\n",
       "      <th>answers</th>\n",
       "      <th>majority_answer</th>\n",
       "      <th>majority_correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ac0351d8649fb60af40c5638061a2e21</th>\n",
       "      <td>chatcmpl-7K6z3XYWOvPh7edXDkJhKGmQwlKek</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1685027761</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>{'prompt_tokens': 75, 'completion_tokens': 140...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "      <td>Answer A, B, C or D. At the end, say 'the answ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>D</td>\n",
       "      <td>[d, d, d, d, d, d, d, d, d, d, d]</td>\n",
       "      <td>d</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      id   \n",
       "question_id                                                                \n",
       "ac0351d8649fb60af40c5638061a2e21  chatcmpl-7K6z3XYWOvPh7edXDkJhKGmQwlKek  \\\n",
       "\n",
       "                                           object     created          model   \n",
       "question_id                                                                    \n",
       "ac0351d8649fb60af40c5638061a2e21  chat.completion  1685027761  gpt-3.5-turbo  \\\n",
       "\n",
       "                                                                              usage   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  {'prompt_tokens': 75, 'completion_tokens': 140...  \\\n",
       "\n",
       "                                                                            choices   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  [{'message': {'role': 'assistant', 'content': ...  \\\n",
       "\n",
       "                                                                           question   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  Answer A, B, C or D. At the end, say 'the answ...  \\\n",
       "\n",
       "                                   n  temperature answerKey   \n",
       "question_id                                                   \n",
       "ac0351d8649fb60af40c5638061a2e21  20          0.7         D  \\\n",
       "\n",
       "                                                            answers   \n",
       "question_id                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  [d, d, d, d, d, d, d, d, d, d, d]  \\\n",
       "\n",
       "                                 majority_answer  majority_correct  \n",
       "question_id                                                         \n",
       "ac0351d8649fb60af40c5638061a2e21               d              True  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_majority(answers: List[str]):\n",
    "    counter = Counter(answers)\n",
    "    return counter.most_common()[0][0]\n",
    "joined[MAJORITY_ANSWER_NAME] = joined[RESPONSE_ANSWERS_NAME].apply(lambda row : get_majority(row))\n",
    "joined[MAJORITY_CORRECT_NAME] = joined.apply(lambda row : COMPARE_ANSWERS(row[MAJORITY_ANSWER_NAME], row[QUESTION_SET_ANSWER_NAME]), axis=1)\n",
    "joined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>object</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>usage</th>\n",
       "      <th>choices</th>\n",
       "      <th>question</th>\n",
       "      <th>n</th>\n",
       "      <th>temperature</th>\n",
       "      <th>answerKey</th>\n",
       "      <th>answers</th>\n",
       "      <th>majority_answer</th>\n",
       "      <th>majority_correct</th>\n",
       "      <th>shannon_entropy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ac0351d8649fb60af40c5638061a2e21</th>\n",
       "      <td>chatcmpl-7K6z3XYWOvPh7edXDkJhKGmQwlKek</td>\n",
       "      <td>chat.completion</td>\n",
       "      <td>1685027761</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>{'prompt_tokens': 75, 'completion_tokens': 140...</td>\n",
       "      <td>[{'message': {'role': 'assistant', 'content': ...</td>\n",
       "      <td>Answer A, B, C or D. At the end, say 'the answ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>D</td>\n",
       "      <td>[d, d, d, d, d, d, d, d, d, d, d]</td>\n",
       "      <td>d</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      id   \n",
       "question_id                                                                \n",
       "ac0351d8649fb60af40c5638061a2e21  chatcmpl-7K6z3XYWOvPh7edXDkJhKGmQwlKek  \\\n",
       "\n",
       "                                           object     created          model   \n",
       "question_id                                                                    \n",
       "ac0351d8649fb60af40c5638061a2e21  chat.completion  1685027761  gpt-3.5-turbo  \\\n",
       "\n",
       "                                                                              usage   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  {'prompt_tokens': 75, 'completion_tokens': 140...  \\\n",
       "\n",
       "                                                                            choices   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  [{'message': {'role': 'assistant', 'content': ...  \\\n",
       "\n",
       "                                                                           question   \n",
       "question_id                                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  Answer A, B, C or D. At the end, say 'the answ...  \\\n",
       "\n",
       "                                   n  temperature answerKey   \n",
       "question_id                                                   \n",
       "ac0351d8649fb60af40c5638061a2e21  20          0.7         D  \\\n",
       "\n",
       "                                                            answers   \n",
       "question_id                                                           \n",
       "ac0351d8649fb60af40c5638061a2e21  [d, d, d, d, d, d, d, d, d, d, d]  \\\n",
       "\n",
       "                                 majority_answer  majority_correct   \n",
       "question_id                                                          \n",
       "ac0351d8649fb60af40c5638061a2e21               d              True  \\\n",
       "\n",
       "                                  shannon_entropy  \n",
       "question_id                                        \n",
       "ac0351d8649fb60af40c5638061a2e21              0.0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined[ENTROPY_COLUMN] = joined[RESPONSE_ANSWERS_NAME].apply(lambda row : ShannonEntropy.base(row))\n",
    "joined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>support</th>\n",
       "      <th>amount_wrong</th>\n",
       "      <th>probability_of_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9741</td>\n",
       "      <td>4294</td>\n",
       "      <td>0.440817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entropy  support  amount_wrong  probability_of_failure\n",
       "0      0.0     9741          4294                0.440817"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_geq(dataframe: pandas.DataFrame, entropy_column: str, correct_column: str):\n",
    "    ret = []\n",
    "    values = dataframe[entropy_column].sort_values().unique().tolist()\n",
    "    for value in values:\n",
    "        filtered_entropy = dataframe[dataframe[entropy_column] >= value]\n",
    "        filtered_wrong = filtered_entropy[~filtered_entropy[correct_column]]\n",
    "        \n",
    "        if len(filtered_entropy) == 0: break\n",
    "        ret.append({\n",
    "            'entropy': value, \n",
    "            'support': len(filtered_entropy), \n",
    "            'amount_wrong': len(filtered_wrong), \n",
    "            'probability_of_failure': len(filtered_wrong) / len(filtered_entropy)\n",
    "        })\n",
    "\n",
    "    return pandas.DataFrame(ret)\n",
    "\n",
    "geq = generate_geq(joined, ENTROPY_COLUMN, MAJORITY_CORRECT_NAME)\n",
    "geq.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_leq(dataframe: pandas.DataFrame, entropy_column: str, correct_column: str):\n",
    "    ret = []\n",
    "    values = dataframe[entropy_column].sort_values().unique().tolist()\n",
    "    for value in values:\n",
    "        filtered_entropy = dataframe[dataframe[entropy_column] <= value]\n",
    "        filtered_wrong = filtered_entropy[~filtered_entropy[correct_column]]\n",
    "        \n",
    "        if len(filtered_entropy) == 0: break\n",
    "        ret.append({\n",
    "            'entropy': value, \n",
    "            'support': len(filtered_entropy), \n",
    "            'amount_wrong': len(filtered_wrong), \n",
    "            'probability_of_failure': len(filtered_wrong) / len(filtered_entropy)\n",
    "        })\n",
    "\n",
    "    return pandas.DataFrame(ret)\n",
    "\n",
    "leq = generate_leq(joined, ENTROPY_COLUMN, MAJORITY_CORRECT_NAME)\n",
    "leq.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = XlsxWorkbook(OUT_FILE_PATH)\n",
    "worksheet = workbook.add_sheet('Entropy_GEQ', geq)\n",
    "worksheet.add_scatter_chart('Entropy vs Probability of failure (GEQ)', 'entropy', 'probability_of_failure', 'H1')\n",
    "\n",
    "worksheet = workbook.add_sheet('Entropy_LEQ', leq)\n",
    "worksheet.add_scatter_chart('Entropy vs Probability of failure (LEQ)', 'entropy', 'probability_of_failure', 'H1')\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
