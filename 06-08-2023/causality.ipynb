{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "\n",
    "\n",
    "from internal_consistency.sympy_solver import Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>equations</th>\n",
       "      <th>category</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/4x + 1/6x = 1\\n3x + 2x = 12\\n5x = 12\\nx = 2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         equations  category  valid\n",
       "0  1/4x + 1/6x = 1\\n3x + 2x = 12\\n5x = 12\\nx = 2.4         2      1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_json('data/output/joined/sample_0.jsonl', lines=True)\n",
    "data['equations'] = data['choices'].apply(lambda row : row[0]['message']['content'])\n",
    "data['valid'] = 1\n",
    "data = data[['equations', 'category', 'valid']]\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>num_of_adds_and_subs__0</th>\n",
       "      <th>num_of_adds_and_subs__1</th>\n",
       "      <th>num_of_adds_and_subs__10</th>\n",
       "      <th>num_of_adds_and_subs__11</th>\n",
       "      <th>num_of_adds_and_subs__12</th>\n",
       "      <th>num_of_adds_and_subs__13</th>\n",
       "      <th>num_of_adds_and_subs__14</th>\n",
       "      <th>num_of_adds_and_subs__15</th>\n",
       "      <th>num_of_adds_and_subs__16</th>\n",
       "      <th>...</th>\n",
       "      <th>pairs_of_parentheses__17</th>\n",
       "      <th>pairs_of_parentheses__2</th>\n",
       "      <th>pairs_of_parentheses__3</th>\n",
       "      <th>pairs_of_parentheses__4</th>\n",
       "      <th>pairs_of_parentheses__5</th>\n",
       "      <th>pairs_of_parentheses__6</th>\n",
       "      <th>pairs_of_parentheses__7</th>\n",
       "      <th>pairs_of_parentheses__8</th>\n",
       "      <th>pairs_of_parentheses__9</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  num_of_adds_and_subs__0  num_of_adds_and_subs__1   \n",
       "0         2                      1.0                      1.0  \\\n",
       "\n",
       "   num_of_adds_and_subs__10  num_of_adds_and_subs__11   \n",
       "0                       0.0                       0.0  \\\n",
       "\n",
       "   num_of_adds_and_subs__12  num_of_adds_and_subs__13   \n",
       "0                       0.0                       0.0  \\\n",
       "\n",
       "   num_of_adds_and_subs__14  num_of_adds_and_subs__15   \n",
       "0                       0.0                       0.0  \\\n",
       "\n",
       "   num_of_adds_and_subs__16  ...  pairs_of_parentheses__17   \n",
       "0                       0.0  ...                       0.0  \\\n",
       "\n",
       "   pairs_of_parentheses__2  pairs_of_parentheses__3  pairs_of_parentheses__4   \n",
       "0                      0.0                      0.0                      0.0  \\\n",
       "\n",
       "   pairs_of_parentheses__5  pairs_of_parentheses__6  pairs_of_parentheses__7   \n",
       "0                      0.0                      0.0                      0.0  \\\n",
       "\n",
       "   pairs_of_parentheses__8  pairs_of_parentheses__9  valid  \n",
       "0                      0.0                      0.0      1  \n",
       "\n",
       "[1 rows x 100 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_geq(row, column_name):\n",
    "    for i in range(row[column_name]):\n",
    "        row[f'{column_name}__{i}'] = 1\n",
    "    return row\n",
    "\n",
    "def num_of_decimals(equations):\n",
    "    return len(re.findall(r'\\d+.\\d+', equations))\n",
    "\n",
    "data['num_of_adds_and_subs'] = data['equations'].apply(lambda row : row.count('+') + row.count('-'))\n",
    "data['num_of_mults_and_divs'] = data['equations'].apply(lambda row : row.count('*') + row.count('/'))\n",
    "data['num_of_equals'] = data['equations'].apply(lambda row : row.count('='))\n",
    "data['pairs_of_parentheses'] = data['equations'].apply(lambda row : row.count('('))\n",
    "data['num_of_decimals'] = data['equations'].apply(lambda row : num_of_decimals(row))\n",
    "data['num_of_unknowns'] = data['equations'].apply(lambda row : len(Standardize.extract_variable_names(row.split('\\n'))))\n",
    "\n",
    "data = data.apply(lambda row: generate_geq(row, 'num_of_adds_and_subs'), axis=1)\n",
    "data = data.apply(lambda row: generate_geq(row, 'num_of_mults_and_divs'), axis=1)\n",
    "data = data.apply(lambda row: generate_geq(row, 'num_of_equals'), axis=1)\n",
    "data = data.apply(lambda row: generate_geq(row, 'pairs_of_parentheses'), axis=1)\n",
    "data = data.apply(lambda row: generate_geq(row, 'num_of_decimals'), axis=1)\n",
    "data = data.apply(lambda row: generate_geq(row, 'num_of_unknowns'), axis=1)\n",
    "data = data.fillna(0)\n",
    "\n",
    "data = data.drop(columns=[\n",
    "    \"num_of_adds_and_subs\", \n",
    "    \"num_of_mults_and_divs\", \n",
    "    \"num_of_equals\", \n",
    "    \"pairs_of_parentheses\", \n",
    "    \"num_of_decimals\", \n",
    "    \"num_of_unknowns\",\n",
    "    \"equations\"\n",
    "])\n",
    "\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load causality_analysis/calculate_causality.py\n",
    "import pandas as pd\n",
    "\n",
    "MAX_NAME_DIFFERENCE = 5\n",
    "\n",
    "class Causality:\n",
    "    @staticmethod\n",
    "    def causality_wrapper(input_df, VALID_COLUMN, EFFECT_COLUMN):\n",
    "        def negation(column):\n",
    "            # negation -- \n",
    "            # OUTPUT: returns a column of 0s and 1s of the negation of [column]. 1s are flipped to 0 and vice versa\n",
    "            # INPUT: [column] should be a column of 0s and 1s\n",
    "            return 1 - column\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def conjunction(column_1, column_2):\n",
    "            # conjunction -- \n",
    "            # output: returns a column of 0s and 1s of the conjunction between [column_1] and [column_2].\n",
    "            # INPUT: [column_1] and [column_2] should be columns of 0s and 1s\n",
    "            return column_1 * column_2\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def disjunction(column_1, column_2):\n",
    "            # disjunction -- \n",
    "            # OUTPUT: returns a column of 0s and 1s of the disjunction between [column_1] and [column_2].\n",
    "            # INPUT: [column_1] and [column_2] should be columns of 0s and 1s\n",
    "            return column_1 | column_2\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def conditional_probability(occurence_column, condition_column):\n",
    "            # conditional_probability -- \n",
    "            # OUTPUT: returns a number which represents the conditional probability p(occurence | condition)\n",
    "            # INPUT: [occurence_column] and [condition_column] should be columns of 0s and 1s\n",
    "            if condition_column.sum() == 0: return 0\n",
    "            return conjunction(occurence_column, condition_column).sum() / condition_column.sum()\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def prior(data):\n",
    "            # prior -- \n",
    "            # OUTPUT: returns a number which represents the prior\n",
    "            # INPUT: [data] should be a Pandas dataframe with the columns [CORRECT_COLUMN] and [VALID_COLUMN].\n",
    "            # TODO : Possible optimizations can be made where we cache the result instead of calling this expensive operation again and again\n",
    "            return conditional_probability(data[EFFECT_COLUMN], data[VALID_COLUMN])\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def is_prima_facie(data, column_name):\n",
    "            # is_prima_facie -- \n",
    "            # OUTPUT: returns a boolean which determines whether the column indicated by [column_name] is a prima facie\n",
    "            # INPUT: [data] should be a Pandas dataframe with the columns [CORRECT_COLUMN] and [VALID_COLUMN].\n",
    "            # INPUT: [column_name] should be a valid column in [data]\n",
    "            # INPUT: The [CORRECT_COLUMN] and [VALID_COLUMN] columns should be columns of 0s and 1s \n",
    "            return conditional_probability(data[EFFECT_COLUMN], data[column_name]) - prior(data) > 0\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def is_cooccur(column_1, column_2):\n",
    "            # is_cooccur -- \n",
    "            # OUTPUT: returns a boolean based on if there is at least one row where both [column_1] and [column_2] is equal to 1\n",
    "            # INPUT: [column_1] and [column_2] should both be columns of 0s and 1s\n",
    "            return conjunction(column_1, column_2).sum() > 0\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def is_same_category(column_name_1, column_name_2):\n",
    "            # same_category -- \n",
    "            # OUTPUT: Returns a boolean signifying whether the [column_name_1] and [column_name_2] are different by [MAX_NAME_DIFFERENCE]\n",
    "            #         If the two words are not different by [MAX_NAME_DIFFERENCE], they are in the same category so it returns true\n",
    "            count = 0\n",
    "            shortest = min(len(column_name_1), len(column_name_2))\n",
    "            for i in range(0, shortest):\n",
    "                if column_name_1[i] == column_name_2[i]:\n",
    "                    count = count + 1\n",
    "            return max(len(column_name_1), len(column_name_2)) - count < MAX_NAME_DIFFERENCE\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def rel(data, column_name):\n",
    "            # rel -- \n",
    "            # OUTPUT: returns a list of the names of other columns which cooccur with [column_name] and are prima facie\n",
    "            # INPUT: [data] should be a Pandas dataframe with the columns [CORRECT_COLUMN] and [VALID_COLUMN].\n",
    "            # INPUT: [column_name] should be a valid column in [data]\n",
    "            # INPUT: The [CORRECT_COLUMN] and [VALID_COLUMN] columns should be columns of 0s and 1s \n",
    "            \n",
    "            # # If it is not a prima facie cause, we don't bother to find its rel\n",
    "            if not is_prima_facie(data,column_name): return[]\n",
    "                \n",
    "            if column_name in [VALID_COLUMN, EFFECT_COLUMN]: return []\n",
    "            \n",
    "            name_list = []\n",
    "            for potential_cause in data.columns:\n",
    "                # Make sure we are not including the [CORRECT_COLUMN] and [VALID_COLUMN] as part of rel\n",
    "                if potential_cause in [EFFECT_COLUMN, VALID_COLUMN, column_name]: continue\n",
    "\n",
    "                # if is_same_category(potential_cause, column_name): continue\n",
    "\n",
    "                if is_cooccur(data[column_name], data[potential_cause]) and is_prima_facie(data, potential_cause):\n",
    "                    name_list.append(potential_cause)\n",
    "            return name_list\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def calculate_causality(data, column_name):\n",
    "            # calculate_causality -- \n",
    "            # OUTPUT: returns a number which represents the causality value of the column indicated by [column_name]\n",
    "            # INPUT: [data] should be a Pandas dataframe with the columns [CORRECT_COLUMN].\n",
    "            # INPUT: [column_name] should be a valid column in [data]\n",
    "            # INPUT: The [CORRECT_COLUMN] and [VALID_COLUMN] columns should be columns of 0s and 1s \n",
    "\n",
    "            # If it's not a prima facie cause, we don't bother to calculate its causality value\n",
    "            if not is_prima_facie(data, column_name):\n",
    "                return \"n/a\"\n",
    "\n",
    "            relateds = rel(data, column_name)\n",
    "            total_probability = 0\n",
    "            for related in relateds:\n",
    "                conj = conjunction(data[column_name], data[related])\n",
    "                negj = conjunction(negation(data[column_name]), data[related])\n",
    "\n",
    "                k = data[column_name].sum() / len(data)\n",
    "                conj = conditional_probability(data[EFFECT_COLUMN], conj)\n",
    "                negj = conditional_probability(data[EFFECT_COLUMN], negj)\n",
    "\n",
    "                # total_probability += k * (conj - negj)\n",
    "                total_probability += (conj - negj)\n",
    "\n",
    "            if (len(relateds) > 0): return total_probability / len(relateds)\n",
    "            return total_probability\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def is_binary_column(data, column_name):\n",
    "            # is_binary_column --\n",
    "            # Checks to see if a column is a column of 1s and 0s\n",
    "            # INPUT: [data] is a dataframe\n",
    "            # INPUT: [column_name] should be the name of a valid column in [data]\n",
    "            return data.apply(lambda row : 0 if (isinstance(row[column_name], int) and (row[column_name] <= 1)) else 1, axis=1).sum() <= 0\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def remove_non_binary_columns(data):\n",
    "            # remove_non_binary_columns --\n",
    "            # Removes all columns that are not 0s or 1s in the dataset\n",
    "            # INPUT: [data] is a dataframe\n",
    "            non_binary = []\n",
    "            for i in data.columns:\n",
    "                if i in [EFFECT_COLUMN, VALID_COLUMN]: continue\n",
    "                if not is_binary_column(data, i):\n",
    "                    non_binary.append(i)\n",
    "\n",
    "            return data.drop(columns=non_binary)\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "        def generate_row(data, column_name):\n",
    "            # generate_row --\n",
    "            # TODO: This is kind of a terrible name but I can't really think of anything more descriptive. If anyone has any ideas, feel free to modify it\n",
    "            # It basically creates a row, which is actually a data frame with all the data that is needed\n",
    "            # OUTPUT: It outputs a row with all the required values\n",
    "            # INPUT: [data] should be a dataframe\n",
    "            # INPUT: [column_name] should be a string representing a valid column in [data]\n",
    "            toReturn = pd.DataFrame({\n",
    "                \"name\": [column_name], \n",
    "                \"support\": conjunction(data[column_name], data[VALID_COLUMN]).sum(),\n",
    "                \"causality\": [calculate_causality(data, column_name)],\n",
    "                \"rel\": ','.join(rel(data, column_name)),\n",
    "                \"conditional_probability\":[conditional_probability(data[EFFECT_COLUMN], data[column_name])], \n",
    "                \"prior\": prior(data),\n",
    "                \"conditional - prior\": conditional_probability(data[EFFECT_COLUMN], data[column_name]) - prior(data)\n",
    "            })\n",
    "            return toReturn\n",
    "            \n",
    "            \"\"\"\"\"\"\n",
    "\n",
    "        def causality_values(input_df):\n",
    "            # causality_values --\n",
    "            # Calculates causality values\n",
    "\n",
    "            # Then remove all the non binary columns\n",
    "            # input_df = remove_non_binary_columns(input_df)\n",
    "\n",
    "            # TODO: This is a hack\n",
    "            # short_names = []\n",
    "            # for column in input_df.columns:\n",
    "            #     if len(column) < 5 and column != VALID_COLUMN and column != EFFECT_COLUMN: short_names.append(column)\n",
    "            # input_df = input_df.drop(columns=short_names, axis=1)\n",
    "\n",
    "            # TODO: I'm not sure if there's another way to do this, so feel free to make modifications\n",
    "            # Generate a dud data frame with a single so we can append to it.\n",
    "            to_save = generate_row(input_df, VALID_COLUMN)\n",
    "            for column in input_df.columns:\n",
    "                if column in [VALID_COLUMN, EFFECT_COLUMN]: continue\n",
    "                to_save = pandas.concat([to_save, generate_row(input_df, column)], axis=0)\n",
    "\n",
    "            # Remove the dud first row\n",
    "            to_save = to_save[1:]\n",
    "            return to_save\n",
    "\n",
    "            \"\"\"\"\"\"\n",
    "\n",
    "        to_return = causality_values(input_df)\n",
    "        return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(1, 17):\n",
    "    causality_df = data.copy()\n",
    "    causality_df['category'] = causality_df['category'].apply(lambda row : 1 if row == index else 0)\n",
    "    causality_df = Causality.causality_wrapper(data, 'valid', 'category')\n",
    "    display(causality_df)\n",
    "    writer = pandas.ExcelWriter(f'data/output/xlsx/sample_0/{index}_causality.xlsx', engine='xlsxwriter')\n",
    "    causality_df.to_excel(writer, sheet_name='List')\n",
    "    writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
