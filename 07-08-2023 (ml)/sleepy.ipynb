{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas\n",
    "from imblearn.pipeline import Pipeline\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import math\n",
    "from typing import Iterable\n",
    "import warnings\n",
    "import tensorflow\n",
    "from sklearn.utils import class_weight\n",
    "import numpy\n",
    "import keras\n",
    "import re\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "\n",
    "tensorflow.get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTES = [\"majority_distance\", \"majority_distance_squared\", \"shannon_entropy\", \"gini_impurity\"]\n",
    "CLASS = 'majority_correct'\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLExploration:\n",
    "    def __init__(self, data_x, data_y, scoring, output_file_path):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.scoring = scoring\n",
    "        self.output_file_path = output_file_path\n",
    "        self.explored_models = pandas.DataFrame()\n",
    "        if os.path.exists(output_file_path): self.explored_models = pandas.read_json(output_file_path, lines=True)\n",
    "\n",
    "    def explore_model(self, clf, sampler):\n",
    "        clf_hash = self.__hash_model(clf)\n",
    "        sampler_hash = self.__hash_model(sampler)\n",
    "        index = str((clf_hash, sampler_hash))\n",
    "        \n",
    "        if (\n",
    "            \"id\" in self.explored_models\n",
    "            and index in self.explored_models['id']\n",
    "        ):\n",
    "            return\n",
    "\n",
    "        if sampler == None:\n",
    "            model = clf\n",
    "        else:\n",
    "            model = Pipeline([(\"sampler\", sampler), (\"clf\", clf)])\n",
    "        try:\n",
    "            results = cross_validate(\n",
    "                estimator=model, X=self.data_x, y=self.data_y, scoring=self.scoring\n",
    "            )\n",
    "\n",
    "            row = pandas.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"id\": index,\n",
    "                        \"clf\": clf_hash,\n",
    "                        \"sampler\": sampler_hash,\n",
    "                        **self.__dict_mean(results),\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            self.explored_models = pandas.concat([self.explored_models, row])\n",
    "            self.explored_models.to_json(self.output_file_path, lines=True, orient='records')\n",
    "        except: pass\n",
    "\n",
    "    def __dict_mean(self, obj):\n",
    "        try:\n",
    "            return sum(obj) / len(obj)\n",
    "        except:\n",
    "            return {\n",
    "                key.replace(\"test_\", \"\"): self.__dict_mean(obj[key])\n",
    "                for key in obj.keys()\n",
    "            }\n",
    "\n",
    "    def __hash_model(self, clf):\n",
    "        if type(clf) == KerasClassifier:\n",
    "            cleaned = re.sub(r'\\n\\tmodel\\=.*\\n', '', str(clf), re.DOTALL)\n",
    "            cleaned = re.sub(r'\\n', ',', cleaned, re.DOTALL)\n",
    "            cleaned = re.sub(r'\\t', '', cleaned, re.DOTALL)\n",
    "            return str((cleaned, self.__keras_model_info(clf)))\n",
    "        return str(clf)\n",
    "\n",
    "    def __keras_model_info(self, clf):\n",
    "        return str(\n",
    "            [\n",
    "                (type(layer).__name__, layer.units, layer.activation.__name__)\n",
    "                for layer in clf.model.layers\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, EditedNearestNeighbours, RandomUnderSampler, InstanceHardnessThreshold\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    \"accuracy\": make_scorer(accuracy_score),\n",
    "    \"precision-Incorrect\": make_scorer(precision_score, pos_label=0),\n",
    "    \"recall-Incorrect\": make_scorer(recall_score, pos_label=0),\n",
    "    \"f1-Incorrect\": make_scorer(f1_score, pos_label=0),\n",
    "    \"precision-Correct\": make_scorer(precision_score, pos_label=1),\n",
    "    \"recall-Correct\": make_scorer(recall_score, pos_label=1),\n",
    "    \"f1-Correct\": make_scorer(f1_score, pos_label=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_features, n_layers, units, hidden_activation, output_activation, step_size=5):\n",
    "    model = Sequential()\n",
    "    step = -step_size\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            model.add(Dense(units, input_dim=n_features, activation=hidden_activation))  \n",
    "        else:\n",
    "            if step == 0: units = max(1, units // 2)\n",
    "            model.add(Dense(units, activation=hidden_activation))\n",
    "        step = (step + 1) % step_size\n",
    "    model.add(Dense(1, activation=output_activation))  \n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path, cache_file_path in [\n",
    "    ('data/draw/draw-T0.3.jsonl', 'cache/draw/draw-T0.3.jsonl'),\n",
    "    ('data/draw/draw-T0.5.jsonl', 'cache/draw/draw-T0.5.json'),\n",
    "    ('data/draw/draw-T0.7.jsonl', 'cache/draw/draw-T0.7.json'),\n",
    "    ('data/csqa/csqa-T0.3.jsonl', 'cache/csqa/csqa-T0.3.json'),\n",
    "    ('data/csqa/csqa-T0.5.jsonl', 'cache/csqa/csqa-T0.5.json'),\n",
    "    ('data/csqa/csqa-T0.7.jsonl', 'cache/csqa/csqa-T0.7.json'),\n",
    "    ('data/last_letters/last_letters-T0.3.jsonl', 'cache/last_letters/last_letters-T0.3.json'),\n",
    "    ('data/last_letters/last_letters-T0.5.jsonl', 'cache/last_letters/last_letters-T0.5.json'),\n",
    "    ('data/last_letters/last_letters-T0.7.jsonl', 'cache/last_letters/last_letters-T0.7.json'),\n",
    "]:\n",
    "    data = pandas.read_json(file_path, lines=True)\n",
    "    data_x = data[ATTRIBUTES]\n",
    "    data_y = data[CLASS]\n",
    "    ml_exploration = MLExploration(\n",
    "        data_x=data_x, data_y=data_y, output_file_path=cache_file_path, scoring=scoring\n",
    "    )\n",
    "    for sampler in [\n",
    "        RandomOverSampler(random_state=RANDOM_STATE),\n",
    "        ADASYN(random_state=RANDOM_STATE),\n",
    "        SMOTE(random_state=RANDOM_STATE),\n",
    "        RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "    ]:\n",
    "        ml_exploration.explore_model(clf=AdaBoostClassifier(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=RandomForestClassifier(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=ExtraTreesClassifier(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=GradientBoostingClassifier(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=KNeighborsClassifier(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=MLPClassifier(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=SVC(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=DecisionTreeClassifier(), sampler=sampler)\n",
    "\n",
    "        ml_exploration.explore_model(clf=KerasClassifier(model=create_model(len(ATTRIBUTES), 5, 100, 'relu', 'sigmoid', step_size=1), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        ml_exploration.explore_model(clf=KerasClassifier(model=create_model(len(ATTRIBUTES), 10, 100, 'relu', 'sigmoid', step_size=2), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        ml_exploration.explore_model(clf=KerasClassifier(model=create_model(len(ATTRIBUTES), 15, 100, 'relu', 'sigmoid', step_size=3), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        ml_exploration.explore_model(clf=KerasClassifier(model=create_model(len(ATTRIBUTES), 25, 100, 'relu', 'sigmoid', step_size=5), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        ml_exploration.explore_model(clf=KerasClassifier(model=create_model(len(ATTRIBUTES), 30, 100, 'relu', 'sigmoid', step_size=6), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
