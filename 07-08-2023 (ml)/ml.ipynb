{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "\n",
    "from lab_v2.io import read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE PATHS\n",
    "DRAW_T03 = './data/draw/draw-T0.3.jsonl' \n",
    "DRAW_T07 = './data/draw/draw-T0.7.jsonl' \n",
    "CSQA_T07 = './data/csqa/csqa-T0.7.jsonl' \n",
    "LAST_LETTERS_T07 = './data/last_letters/last_letters-T0.7.jsonl' \n",
    "\n",
    "ATTRIBUTES = [\"majority_distance\", \"majority_distance_squared\", \"shannon_entropy\", \"gini_impurity\"]\n",
    "CLASS = 'majority_correct'\n",
    "K_FOLDS = 5\n",
    "RANDOM_STATE = 0\n",
    "FILE_PATH = CSQA_T07\n",
    "\n",
    "CACHE = 'cache/csqa/csqa-T0.3.json'\n",
    "CACHE_ROS = 'cache/csqa/csqa-T0.3-ROS.json'\n",
    "\n",
    "DATA_EXPLORATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>majority_distance</th>\n",
       "      <th>majority_distance_squared</th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>gini_impurity</th>\n",
       "      <th>majority_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.378000e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   majority_distance  majority_distance_squared  shannon_entropy   \n",
       "0       1.378000e-07                        0.0              0.0  \\\n",
       "\n",
       "   gini_impurity  majority_correct  \n",
       "0            0.0              True  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_file(FILE_PATH)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_EXPLORATION:\n",
    "    fig = px.scatter_3d(data, x='majority_distance', y='shannon_entropy', z='gini_impurity', color=CLASS, \n",
    "                        color_discrete_sequence=[px.colors.sequential.Plasma_r[3], px.colors.sequential.Plasma_r[-1]])\n",
    "    fig.update_traces(marker=dict(size=3), selector=dict(mode='markers'))\n",
    "    fig.update_traces(marker=dict(opacity=0.75), selector=dict(mode='markers'))\n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_EXPLORATION:\n",
    "    seaborn.set_theme(style='ticks')\n",
    "    seaborn.pairplot(data, hue=\"majority_correct\", plot_kws={'alpha': 0.4})\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data[ATTRIBUTES]\n",
    "data_y = data[CLASS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_reports = []\n",
    "def classification_report_scorer(y_true, y_pred):\n",
    "    classification_reports.append(classification_report(y_true, y_pred))\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_average(*args):\n",
    "    report_list = list()\n",
    "    for report in args:\n",
    "        splited = [' '.join(x.split()) for x in report.split('\\n\\n')]\n",
    "        header = [x for x in splited[0].split(' ')]\n",
    "        data = numpy.array(splited[1].split(' ')).reshape(-1, len(header) + 1)\n",
    "        data = numpy.delete(data, 0, 1).astype(float)\n",
    "        rest = splited[2].split(' ')\n",
    "        accuarcy =numpy.array([0, 0, rest[1], rest[2]]).astype(float).reshape(-1, len(header))\n",
    "        macro_avg = numpy.array([rest[5:9]]).astype(float).reshape(-1, len(header))\n",
    "        weighted_avg = numpy.array([rest[11:]]).astype(float).reshape(-1, len(header))\n",
    "        #avg_total = numpy.array([x for x in avg]).astype(float).reshape(-1, len(header))\n",
    "        df = pandas.DataFrame(numpy.concatenate((data, accuarcy,macro_avg,weighted_avg)), columns=header)\n",
    "        report_list.append(df)\n",
    "    res = reduce(lambda x, y: x.add(y, fill_value=0), report_list) / len(report_list)\n",
    "    return res.rename(index={res.index[-3]: 'accuracy',res.index[-2]: 'macro_avg',res.index[-1]: 'weighted_avg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportAverage:\n",
    "    def __init__(self):\n",
    "        self.classification_reports = []\n",
    "\n",
    "    def classification_report_scorer(self, y_true, y_pred):\n",
    "        self.classification_reports.append(classification_report(y_true, y_pred))\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    def average_report(self):\n",
    "        average = report_average(*self.classification_reports)\n",
    "        return {\n",
    "            'precision_True': average.loc[0]['precision'],\n",
    "            'recall_True': average.loc[0]['recall'],\n",
    "            'f1-score_True': average.loc[0]['f1-score'],\n",
    "            'precision_False': average.loc[1]['precision'],\n",
    "            'recall_False': average.loc[1]['recall'],\n",
    "            'f1-score_False': average.loc[1]['f1-score'],\n",
    "            'f1-score_Average': (average.loc[0]['f1-score'] + average.loc[1]['f1-score']) / 2,\n",
    "            'accuracy': average.loc['accuracy']['f1-score']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cross_validate(model, sampler, data_x, data_y, scoring, cv=5):\n",
    "    kfold = KFold(n_splits=cv)\n",
    "    results = []\n",
    "    for train_idx, test_idx, in kfold.split(data_x):\n",
    "        X_train, X_test = data_x.iloc[train_idx], data_x.iloc[test_idx]\n",
    "        y_train, y_test = data_y.iloc[train_idx], data_y.iloc[test_idx]\n",
    "        \n",
    "        if sampler != None: X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        results.append(scoring(y_test, y_pred))\n",
    "    return sum(results) / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision_True': 0.72,\n",
       " 'recall_True': 0.392,\n",
       " 'f1-score_True': 0.51,\n",
       " 'precision_False': 0.648,\n",
       " 'recall_False': 0.8780000000000001,\n",
       " 'f1-score_False': 0.7460000000000001,\n",
       " 'f1-score_Average': 0.6280000000000001,\n",
       " 'accuracy': 0.664}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = ReportAverage()\n",
    "my_cross_validate(RandomForestClassifier(), RandomOverSampler(), data_x, data_y, scoring=scorer.classification_report_scorer, cv=K_FOLDS)\n",
    "scorer.average_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLExploration:\n",
    "    TEMPLATE_DICT = {\n",
    "        'model': '', \n",
    "        'hyperparameters': '', \n",
    "        'precision_True': '', \n",
    "        'recall_True': '', \n",
    "        'f1-score_True': '', \n",
    "        'precision_False': '', \n",
    "        'recall_False': '', \n",
    "        'f1-score_False': '',\n",
    "        'f1-score_Average': 0,\n",
    "        'accuracy': ''\n",
    "    }\n",
    "    RANDOM_STATE = 42\n",
    "\n",
    "    def __init__(self, data_x, data_y, output_file_path, sampler=None):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.output_file_path = output_file_path\n",
    "        self.sampler = sampler\n",
    "        self.explored_models = pandas.DataFrame([MLExploration.TEMPLATE_DICT])\n",
    "        if os.path.exists(output_file_path): \n",
    "            self.explored_models = pandas.read_json(output_file_path, orient='split')\n",
    "\n",
    "    def grid_search(self, model, parameters):\n",
    "        parameter_combinations = self.__parameter_product(parameters)\n",
    "        for combination in parameter_combinations:\n",
    "            print(combination)\n",
    "            self.explore_model(model, combination)\n",
    "\n",
    "    def explore_model(self, model, hyperparameters):\n",
    "        index = MLExploration.hash(model, hyperparameters)\n",
    "        if index in self.explored_models.index: return self.explored_models.loc[index]\n",
    "\n",
    "        scorer = ReportAverage()\n",
    "        my_cross_validate(model(**hyperparameters), self.sampler, data_x, data_y, scoring=scorer.classification_report_scorer)\n",
    "\n",
    "        self.explored_models.loc[index] = [\n",
    "            MLExploration.hash_model(model), \n",
    "            MLExploration.hash_hyperparameters(hyperparameters),\n",
    "            *scorer.average_report().values()\n",
    "        ]\n",
    "        self.explored_models.to_json(self.output_file_path, orient='split')\n",
    "\n",
    "    def hash_model(model):\n",
    "        return str(model.__name__)\n",
    "    \n",
    "    def hash_hyperparameters(hyperparameters):\n",
    "       return str(sorted(hyperparameters.items(), key=lambda x:x[0]))\n",
    "    \n",
    "    def hash(model, hyperparameters):\n",
    "        model = MLExploration.hash_model(model)\n",
    "        hyperparameters = MLExploration.hash_hyperparameters(hyperparameters)\n",
    "        return str((model, hyperparameters))\n",
    "    \n",
    "    def __parameter_product(self, parameters):\n",
    "        keys, values = zip(*parameters.items())\n",
    "        experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "        return experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_scorer(y_true, y_pred):\n",
    "    classification_report(y_true, y_pred) # print classification report\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "csqa = MLExploration(data_x, data_y, CACHE, RandomOverSampler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_BaseScorer.__call__() missing 1 required positional argument: 'y_true'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m csqa\u001b[39m.\u001b[39;49mexplore_model(AdaBoostClassifier, {})\n\u001b[0;32m      2\u001b[0m csqa\u001b[39m.\u001b[39mexplore_model(RandomForestClassifier, {})\n\u001b[0;32m      3\u001b[0m csqa\u001b[39m.\u001b[39mexplore_model(ExtraTreesClassifier, {})\n",
      "Cell \u001b[1;32mIn[122], line 36\u001b[0m, in \u001b[0;36mMLExploration.explore_model\u001b[1;34m(self, model, hyperparameters)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplored_models\u001b[39m.\u001b[39mindex: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplored_models\u001b[39m.\u001b[39mloc[index]\n\u001b[0;32m     35\u001b[0m scorer \u001b[39m=\u001b[39m ReportAverage()\n\u001b[1;32m---> 36\u001b[0m my_cross_validate(model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhyperparameters), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampler, data_x, data_y, scoring\u001b[39m=\u001b[39;49mmake_scorer(scorer\u001b[39m.\u001b[39;49mclassification_report_scorer))\n\u001b[0;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplored_models\u001b[39m.\u001b[39mloc[index] \u001b[39m=\u001b[39m [\n\u001b[0;32m     39\u001b[0m     MLExploration\u001b[39m.\u001b[39mhash_model(model), \n\u001b[0;32m     40\u001b[0m     MLExploration\u001b[39m.\u001b[39mhash_hyperparameters(hyperparameters),\n\u001b[0;32m     41\u001b[0m     \u001b[39m*\u001b[39mscorer\u001b[39m.\u001b[39maverage_report()\u001b[39m.\u001b[39mvalues()\n\u001b[0;32m     42\u001b[0m ]\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplored_models\u001b[39m.\u001b[39mto_json(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_file_path, orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[120], line 12\u001b[0m, in \u001b[0;36mmy_cross_validate\u001b[1;34m(model, sampler, data_x, data_y, scoring, cv)\u001b[0m\n\u001b[0;32m      9\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     11\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 12\u001b[0m     results\u001b[39m.\u001b[39mappend(scoring(y_test, y_pred))\n\u001b[0;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(results) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(results)\n",
      "\u001b[1;31mTypeError\u001b[0m: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'"
     ]
    }
   ],
   "source": [
    "csqa.explore_model(AdaBoostClassifier, {})\n",
    "csqa.explore_model(RandomForestClassifier, {})\n",
    "csqa.explore_model(ExtraTreesClassifier, {})\n",
    "csqa.explore_model(GradientBoostingClassifier, {})\n",
    "csqa.explore_model(GaussianProcessClassifier, {})\n",
    "csqa.explore_model(GaussianNB, {})\n",
    "csqa.explore_model(KNeighborsClassifier, {})\n",
    "csqa.explore_model(MLPClassifier, {})\n",
    "csqa.explore_model(SVC, {})\n",
    "csqa.explore_model(DecisionTreeClassifier, {})\n",
    "csqa.explored_models.sort_values(by='f1-score_Average').style.hide(axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "ros = ADASYN(random_state=RANDOM_STATE)\n",
    "ros = SMOTE(random_state=RANDOM_STATE)\n",
    "data_x_resampled, data_y_resampled = ros.fit_resample(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csqa_ros = MLExploration(data_x_resampled, data_y_resampled, CACHE_ROS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a12ed\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_a12ed_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n",
       "      <th id=\"T_a12ed_level0_col1\" class=\"col_heading level0 col1\" >hyperparameters</th>\n",
       "      <th id=\"T_a12ed_level0_col2\" class=\"col_heading level0 col2\" >precision_True</th>\n",
       "      <th id=\"T_a12ed_level0_col3\" class=\"col_heading level0 col3\" >recall_True</th>\n",
       "      <th id=\"T_a12ed_level0_col4\" class=\"col_heading level0 col4\" >f1-score_True</th>\n",
       "      <th id=\"T_a12ed_level0_col5\" class=\"col_heading level0 col5\" >precision_False</th>\n",
       "      <th id=\"T_a12ed_level0_col6\" class=\"col_heading level0 col6\" >recall_False</th>\n",
       "      <th id=\"T_a12ed_level0_col7\" class=\"col_heading level0 col7\" >f1-score_False</th>\n",
       "      <th id=\"T_a12ed_level0_col8\" class=\"col_heading level0 col8\" >f1-score_Average</th>\n",
       "      <th id=\"T_a12ed_level0_col9\" class=\"col_heading level0 col9\" >accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row0_col0\" class=\"data row0 col0\" ></td>\n",
       "      <td id=\"T_a12ed_row0_col1\" class=\"data row0 col1\" ></td>\n",
       "      <td id=\"T_a12ed_row0_col2\" class=\"data row0 col2\" ></td>\n",
       "      <td id=\"T_a12ed_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_a12ed_row0_col4\" class=\"data row0 col4\" ></td>\n",
       "      <td id=\"T_a12ed_row0_col5\" class=\"data row0 col5\" ></td>\n",
       "      <td id=\"T_a12ed_row0_col6\" class=\"data row0 col6\" ></td>\n",
       "      <td id=\"T_a12ed_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "      <td id=\"T_a12ed_row0_col8\" class=\"data row0 col8\" >0.000000</td>\n",
       "      <td id=\"T_a12ed_row0_col9\" class=\"data row0 col9\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row1_col0\" class=\"data row1 col0\" >AdaBoostClassifier</td>\n",
       "      <td id=\"T_a12ed_row1_col1\" class=\"data row1 col1\" >[]</td>\n",
       "      <td id=\"T_a12ed_row1_col2\" class=\"data row1 col2\" >0.456000</td>\n",
       "      <td id=\"T_a12ed_row1_col3\" class=\"data row1 col3\" >0.276000</td>\n",
       "      <td id=\"T_a12ed_row1_col4\" class=\"data row1 col4\" >0.338000</td>\n",
       "      <td id=\"T_a12ed_row1_col5\" class=\"data row1 col5\" >0.842000</td>\n",
       "      <td id=\"T_a12ed_row1_col6\" class=\"data row1 col6\" >0.920000</td>\n",
       "      <td id=\"T_a12ed_row1_col7\" class=\"data row1 col7\" >0.878000</td>\n",
       "      <td id=\"T_a12ed_row1_col8\" class=\"data row1 col8\" >0.608000</td>\n",
       "      <td id=\"T_a12ed_row1_col9\" class=\"data row1 col9\" >0.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row2_col0\" class=\"data row2 col0\" >DecisionTreeClassifier</td>\n",
       "      <td id=\"T_a12ed_row2_col1\" class=\"data row2 col1\" >[]</td>\n",
       "      <td id=\"T_a12ed_row2_col2\" class=\"data row2 col2\" >0.712000</td>\n",
       "      <td id=\"T_a12ed_row2_col3\" class=\"data row2 col3\" >0.368000</td>\n",
       "      <td id=\"T_a12ed_row2_col4\" class=\"data row2 col4\" >0.482000</td>\n",
       "      <td id=\"T_a12ed_row2_col5\" class=\"data row2 col5\" >0.638000</td>\n",
       "      <td id=\"T_a12ed_row2_col6\" class=\"data row2 col6\" >0.880000</td>\n",
       "      <td id=\"T_a12ed_row2_col7\" class=\"data row2 col7\" >0.742000</td>\n",
       "      <td id=\"T_a12ed_row2_col8\" class=\"data row2 col8\" >0.612000</td>\n",
       "      <td id=\"T_a12ed_row2_col9\" class=\"data row2 col9\" >0.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row3_col0\" class=\"data row3 col0\" >KNeighborsClassifier</td>\n",
       "      <td id=\"T_a12ed_row3_col1\" class=\"data row3 col1\" >[]</td>\n",
       "      <td id=\"T_a12ed_row3_col2\" class=\"data row3 col2\" >0.612000</td>\n",
       "      <td id=\"T_a12ed_row3_col3\" class=\"data row3 col3\" >0.486000</td>\n",
       "      <td id=\"T_a12ed_row3_col4\" class=\"data row3 col4\" >0.540000</td>\n",
       "      <td id=\"T_a12ed_row3_col5\" class=\"data row3 col5\" >0.650000</td>\n",
       "      <td id=\"T_a12ed_row3_col6\" class=\"data row3 col6\" >0.758000</td>\n",
       "      <td id=\"T_a12ed_row3_col7\" class=\"data row3 col7\" >0.698000</td>\n",
       "      <td id=\"T_a12ed_row3_col8\" class=\"data row3 col8\" >0.619000</td>\n",
       "      <td id=\"T_a12ed_row3_col9\" class=\"data row3 col9\" >0.634000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row4_col0\" class=\"data row4 col0\" >RandomForestClassifier</td>\n",
       "      <td id=\"T_a12ed_row4_col1\" class=\"data row4 col1\" >[]</td>\n",
       "      <td id=\"T_a12ed_row4_col2\" class=\"data row4 col2\" >0.714000</td>\n",
       "      <td id=\"T_a12ed_row4_col3\" class=\"data row4 col3\" >0.386000</td>\n",
       "      <td id=\"T_a12ed_row4_col4\" class=\"data row4 col4\" >0.502000</td>\n",
       "      <td id=\"T_a12ed_row4_col5\" class=\"data row4 col5\" >0.644000</td>\n",
       "      <td id=\"T_a12ed_row4_col6\" class=\"data row4 col6\" >0.876000</td>\n",
       "      <td id=\"T_a12ed_row4_col7\" class=\"data row4 col7\" >0.744000</td>\n",
       "      <td id=\"T_a12ed_row4_col8\" class=\"data row4 col8\" >0.623000</td>\n",
       "      <td id=\"T_a12ed_row4_col9\" class=\"data row4 col9\" >0.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row5_col0\" class=\"data row5 col0\" >GaussianNB</td>\n",
       "      <td id=\"T_a12ed_row5_col1\" class=\"data row5 col1\" >[]</td>\n",
       "      <td id=\"T_a12ed_row5_col2\" class=\"data row5 col2\" >0.750000</td>\n",
       "      <td id=\"T_a12ed_row5_col3\" class=\"data row5 col3\" >0.386000</td>\n",
       "      <td id=\"T_a12ed_row5_col4\" class=\"data row5 col4\" >0.510000</td>\n",
       "      <td id=\"T_a12ed_row5_col5\" class=\"data row5 col5\" >0.650000</td>\n",
       "      <td id=\"T_a12ed_row5_col6\" class=\"data row5 col6\" >0.898000</td>\n",
       "      <td id=\"T_a12ed_row5_col7\" class=\"data row5 col7\" >0.752000</td>\n",
       "      <td id=\"T_a12ed_row5_col8\" class=\"data row5 col8\" >0.631000</td>\n",
       "      <td id=\"T_a12ed_row5_col9\" class=\"data row5 col9\" >0.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row6_col0\" class=\"data row6 col0\" >SVC</td>\n",
       "      <td id=\"T_a12ed_row6_col1\" class=\"data row6 col1\" >[]</td>\n",
       "      <td id=\"T_a12ed_row6_col2\" class=\"data row6 col2\" >0.758000</td>\n",
       "      <td id=\"T_a12ed_row6_col3\" class=\"data row6 col3\" >0.384000</td>\n",
       "      <td id=\"T_a12ed_row6_col4\" class=\"data row6 col4\" >0.510000</td>\n",
       "      <td id=\"T_a12ed_row6_col5\" class=\"data row6 col5\" >0.648000</td>\n",
       "      <td id=\"T_a12ed_row6_col6\" class=\"data row6 col6\" >0.904000</td>\n",
       "      <td id=\"T_a12ed_row6_col7\" class=\"data row6 col7\" >0.756000</td>\n",
       "      <td id=\"T_a12ed_row6_col8\" class=\"data row6 col8\" >0.633000</td>\n",
       "      <td id=\"T_a12ed_row6_col9\" class=\"data row6 col9\" >0.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row7_col0\" class=\"data row7 col0\" >MLPClassifier</td>\n",
       "      <td id=\"T_a12ed_row7_col1\" class=\"data row7 col1\" >[]</td>\n",
       "      <td id=\"T_a12ed_row7_col2\" class=\"data row7 col2\" >0.746000</td>\n",
       "      <td id=\"T_a12ed_row7_col3\" class=\"data row7 col3\" >0.396000</td>\n",
       "      <td id=\"T_a12ed_row7_col4\" class=\"data row7 col4\" >0.516000</td>\n",
       "      <td id=\"T_a12ed_row7_col5\" class=\"data row7 col5\" >0.652000</td>\n",
       "      <td id=\"T_a12ed_row7_col6\" class=\"data row7 col6\" >0.894000</td>\n",
       "      <td id=\"T_a12ed_row7_col7\" class=\"data row7 col7\" >0.754000</td>\n",
       "      <td id=\"T_a12ed_row7_col8\" class=\"data row7 col8\" >0.635000</td>\n",
       "      <td id=\"T_a12ed_row7_col9\" class=\"data row7 col9\" >0.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row8_col0\" class=\"data row8 col0\" >ExtraTreesClassifier</td>\n",
       "      <td id=\"T_a12ed_row8_col1\" class=\"data row8 col1\" >[]</td>\n",
       "      <td id=\"T_a12ed_row8_col2\" class=\"data row8 col2\" >0.432000</td>\n",
       "      <td id=\"T_a12ed_row8_col3\" class=\"data row8 col3\" >0.418000</td>\n",
       "      <td id=\"T_a12ed_row8_col4\" class=\"data row8 col4\" >0.428000</td>\n",
       "      <td id=\"T_a12ed_row8_col5\" class=\"data row8 col5\" >0.862000</td>\n",
       "      <td id=\"T_a12ed_row8_col6\" class=\"data row8 col6\" >0.868000</td>\n",
       "      <td id=\"T_a12ed_row8_col7\" class=\"data row8 col7\" >0.866000</td>\n",
       "      <td id=\"T_a12ed_row8_col8\" class=\"data row8 col8\" >0.647000</td>\n",
       "      <td id=\"T_a12ed_row8_col9\" class=\"data row8 col9\" >0.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row9_col0\" class=\"data row9 col0\" >GradientBoostingClassifier</td>\n",
       "      <td id=\"T_a12ed_row9_col1\" class=\"data row9 col1\" >[]</td>\n",
       "      <td id=\"T_a12ed_row9_col2\" class=\"data row9 col2\" >0.530000</td>\n",
       "      <td id=\"T_a12ed_row9_col3\" class=\"data row9 col3\" >0.340000</td>\n",
       "      <td id=\"T_a12ed_row9_col4\" class=\"data row9 col4\" >0.416000</td>\n",
       "      <td id=\"T_a12ed_row9_col5\" class=\"data row9 col5\" >0.858000</td>\n",
       "      <td id=\"T_a12ed_row9_col6\" class=\"data row9 col6\" >0.928000</td>\n",
       "      <td id=\"T_a12ed_row9_col7\" class=\"data row9 col7\" >0.890000</td>\n",
       "      <td id=\"T_a12ed_row9_col8\" class=\"data row9 col8\" >0.653000</td>\n",
       "      <td id=\"T_a12ed_row9_col9\" class=\"data row9 col9\" >0.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a12ed_row10_col0\" class=\"data row10 col0\" >GaussianProcessClassifier</td>\n",
       "      <td id=\"T_a12ed_row10_col1\" class=\"data row10 col1\" >[]</td>\n",
       "      <td id=\"T_a12ed_row10_col2\" class=\"data row10 col2\" >0.600000</td>\n",
       "      <td id=\"T_a12ed_row10_col3\" class=\"data row10 col3\" >0.362000</td>\n",
       "      <td id=\"T_a12ed_row10_col4\" class=\"data row10 col4\" >0.452000</td>\n",
       "      <td id=\"T_a12ed_row10_col5\" class=\"data row10 col5\" >0.860000</td>\n",
       "      <td id=\"T_a12ed_row10_col6\" class=\"data row10 col6\" >0.940000</td>\n",
       "      <td id=\"T_a12ed_row10_col7\" class=\"data row10 col7\" >0.898000</td>\n",
       "      <td id=\"T_a12ed_row10_col8\" class=\"data row10 col8\" >0.675000</td>\n",
       "      <td id=\"T_a12ed_row10_col9\" class=\"data row10 col9\" >0.828000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a5c2c98890>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csqa_ros.explore_model(AdaBoostClassifier, {})\n",
    "csqa_ros.explore_model(RandomForestClassifier, {})\n",
    "csqa_ros.explore_model(ExtraTreesClassifier, {})\n",
    "csqa_ros.explore_model(GradientBoostingClassifier, {})\n",
    "csqa_ros.explore_model(GaussianProcessClassifier, {})\n",
    "csqa_ros.explore_model(GaussianNB, {})\n",
    "csqa_ros.explore_model(KNeighborsClassifier, {})\n",
    "csqa_ros.explore_model(MLPClassifier, {})\n",
    "csqa_ros.explore_model(SVC, {})\n",
    "csqa_ros.explore_model(DecisionTreeClassifier, {})\n",
    "csqa_ros.explored_models.sort_values(by='f1-score_Average').style.hide(axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cross_validate(data_x, data_y, model, sampler, scoring, k_folds=5):\n",
    "    cv = StratifiedKFold(n_splits=k_folds)\n",
    "    results = []\n",
    "    for train_idx, test_idx, in cv.split(data_x, data_y):\n",
    "        X_train, y_train = data_x[train_idx], data_y[train_idx]\n",
    "        X_test, y_test = data_x[test_idx], data_y[test_idx]\n",
    "        X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        results.append(scoring(y_test, y_pred))\n",
    "    return sum(results) / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
