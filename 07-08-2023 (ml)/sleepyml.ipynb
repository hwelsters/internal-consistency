{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "\n",
    "from lab_v2.io import read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE PATHS\n",
    "DRAW_T03 = './data/draw/draw-T0.3.jsonl' \n",
    "DRAW_T07 = './data/draw/draw-T0.7.jsonl' \n",
    "CSQA_T07 = './data/csqa/csqa-T0.7.jsonl' \n",
    "LAST_LETTERS_T07 = './data/last_letters/last_letters-T0.7.jsonl' \n",
    "\n",
    "ATTRIBUTES = [\"majority_distance\", \"majority_distance_squared\", \"shannon_entropy\", \"gini_impurity\"]\n",
    "CLASS = 'majority_correct'\n",
    "K_FOLDS = 5\n",
    "RANDOM_STATE = 0\n",
    "FILE_PATH = CSQA_T07\n",
    "\n",
    "CACHE = 'cache/csqa/csqa-T0.3.json'\n",
    "CACHE_ROS = 'cache/csqa/csqa-T0.3-ROS.json'\n",
    "\n",
    "DATA_EXPLORATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>majority_distance</th>\n",
       "      <th>majority_distance_squared</th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>gini_impurity</th>\n",
       "      <th>majority_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.378000e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   majority_distance  majority_distance_squared  shannon_entropy   \n",
       "0       1.378000e-07                        0.0              0.0  \\\n",
       "\n",
       "   gini_impurity  majority_correct  \n",
       "0            0.0              True  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_file(FILE_PATH)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_EXPLORATION:\n",
    "    fig = px.scatter_3d(data, x='majority_distance', y='shannon_entropy', z='gini_impurity', color=CLASS, \n",
    "                        color_discrete_sequence=[px.colors.sequential.Plasma_r[3], px.colors.sequential.Plasma_r[-1]])\n",
    "    fig.update_traces(marker=dict(size=3), selector=dict(mode='markers'))\n",
    "    fig.update_traces(marker=dict(opacity=0.75), selector=dict(mode='markers'))\n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_EXPLORATION:\n",
    "    seaborn.set_theme(style='ticks')\n",
    "    seaborn.pairplot(data, hue=\"majority_correct\", plot_kws={'alpha': 0.4})\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data[ATTRIBUTES]\n",
    "data_y = data[CLASS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_reports = []\n",
    "def classification_report_scorer(y_true, y_pred):\n",
    "    classification_reports.append(classification_report(y_true, y_pred))\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_average(*args):\n",
    "    report_list = list()\n",
    "    for report in args:\n",
    "        splited = [' '.join(x.split()) for x in report.split('\\n\\n')]\n",
    "        header = [x for x in splited[0].split(' ')]\n",
    "        data = numpy.array(splited[1].split(' ')).reshape(-1, len(header) + 1)\n",
    "        data = numpy.delete(data, 0, 1).astype(float)\n",
    "        rest = splited[2].split(' ')\n",
    "        accuarcy =numpy.array([0, 0, rest[1], rest[2]]).astype(float).reshape(-1, len(header))\n",
    "        macro_avg = numpy.array([rest[5:9]]).astype(float).reshape(-1, len(header))\n",
    "        weighted_avg = numpy.array([rest[11:]]).astype(float).reshape(-1, len(header))\n",
    "        df = pandas.DataFrame(numpy.concatenate((data, accuarcy,macro_avg,weighted_avg)), columns=header)\n",
    "        report_list.append(df)\n",
    "    res = reduce(lambda x, y: x.add(y, fill_value=0), report_list) / len(report_list)\n",
    "    return res.rename(index={res.index[-3]: 'accuracy',res.index[-2]: 'macro_avg',res.index[-1]: 'weighted_avg'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportAverage:\n",
    "    def __init__(self):\n",
    "        self.classification_reports = []\n",
    "\n",
    "    def classification_report_scorer(self, y_true, y_pred):\n",
    "        self.classification_reports.append(classification_report(y_true, y_pred))\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    def average_report(self):\n",
    "        average = report_average(*self.classification_reports)\n",
    "        return {\n",
    "            'precision_True': average.loc[0]['precision'],\n",
    "            'recall_True': average.loc[0]['recall'],\n",
    "            'f1-score_True': average.loc[0]['f1-score'],\n",
    "            'precision_False': average.loc[1]['precision'],\n",
    "            'recall_False': average.loc[1]['recall'],\n",
    "            'f1-score_False': average.loc[1]['f1-score'],\n",
    "            'f1-score_Average': (average.loc[0]['f1-score'] + average.loc[1]['f1-score']) / 2,\n",
    "            'accuracy': average.loc['accuracy']['f1-score']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cross_validate(model, sampler, data_x, data_y, scoring, cv=5):\n",
    "    kfold = KFold(n_splits=cv)\n",
    "    results = []\n",
    "    for train_idx, test_idx, in kfold.split(data_x):\n",
    "        X_train, X_test = data_x.iloc[train_idx], data_x.iloc[test_idx]\n",
    "        y_train, y_test = data_y.iloc[train_idx], data_y.iloc[test_idx]\n",
    "        \n",
    "        if sampler != None: X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        results.append(scoring(y_test, y_pred))\n",
    "    return sum(results) / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLExploration:\n",
    "    TEMPLATE_DICT = {\n",
    "        'sampler': '',\n",
    "        'model': '', \n",
    "        'hyperparameters': '', \n",
    "        'precision_True': 0, \n",
    "        'recall_True': 0, \n",
    "        'f1-score_True': 0, \n",
    "        'precision_False': 0, \n",
    "        'recall_False': 0, \n",
    "        'f1-score_False': 0,\n",
    "        'f1-score_Average': 0,\n",
    "        'accuracy': 0\n",
    "    }\n",
    "\n",
    "    def __init__(self, data_x, data_y, output_file_path):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.output_file_path = output_file_path\n",
    "        self.explored_models = pandas.DataFrame([MLExploration.TEMPLATE_DICT])\n",
    "        if os.path.exists(output_file_path): \n",
    "            self.explored_models = pandas.read_json(output_file_path, orient='split')\n",
    "\n",
    "    def grid_search(self, sampler, model, parameters):\n",
    "        parameter_combinations = self.__parameter_product(parameters)\n",
    "        for combination in parameter_combinations:\n",
    "            print(combination)\n",
    "            self.explore_model(model, combination, sampler)\n",
    "\n",
    "    def explore_model(self, model, hyperparameters, sampler=None):\n",
    "        if type(model) == KerasClassifier: model_hash = model(**hyperparameters)\n",
    "        else: model_hash = model\n",
    "\n",
    "        index = MLExploration.hash(model_hash, hyperparameters, sampler)\n",
    "        if index in self.explored_models.index: return self.explored_models.loc[index]\n",
    "        print(index)\n",
    "        print(model_hash)\n",
    "        print(type(model_hash))\n",
    "\n",
    "        scorer = ReportAverage()\n",
    "        my_cross_validate(model(**hyperparameters), sampler, data_x, data_y, scoring=scorer.classification_report_scorer)\n",
    "\n",
    "        self.explored_models.loc[index] = [\n",
    "            MLExploration.hash_sampler(sampler),\n",
    "            MLExploration.hash_model(model_hash), \n",
    "            MLExploration.hash_hyperparameters(hyperparameters),\n",
    "            *scorer.average_report().values()\n",
    "        ]\n",
    "        self.explored_models.to_json(self.output_file_path, orient='split')\n",
    "\n",
    "    def hash_sampler(sampler):\n",
    "        return str(sampler)\n",
    "    \n",
    "    def hash_model(clf):\n",
    "        if type(clf) == KerasClassifier:\n",
    "            return MLExploration.__keras_model_info(clf)\n",
    "        return str(clf)\n",
    "\n",
    "    def __keras_model_info(clf):\n",
    "        return str(\n",
    "            [\n",
    "                (type(layer).__name__, layer.units, layer.activation.__name__)\n",
    "                for layer in clf.model.layers\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def hash_hyperparameters(hyperparameters):\n",
    "       return str(sorted(hyperparameters.items(), key=lambda x:x[0]))\n",
    "    \n",
    "    def hash(model, hyperparameters, sampler):\n",
    "        sampler = MLExploration.hash_sampler(sampler)\n",
    "        model = MLExploration.hash_model(model)\n",
    "        hyperparameters = MLExploration.hash_hyperparameters(hyperparameters)\n",
    "        return str((sampler, model, hyperparameters))\n",
    "    \n",
    "    def __parameter_product(self, parameters):\n",
    "        keys, values = zip(*parameters.items())\n",
    "        experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "        return experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, EditedNearestNeighbours, RandomUnderSampler, InstanceHardnessThreshold\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_scorer(y_true, y_pred):\n",
    "    classification_report(y_true, y_pred) # print classification report\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KerasClassifier stuff\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_model(layers=5, units=100, step_size=1):\n",
    "    model = Sequential()\n",
    "    step = -step_size\n",
    "    for i in range(layers):\n",
    "        if i == 0:\n",
    "            model.add(Dense(units, input_dim=4, activation='relu'))  \n",
    "        else:\n",
    "            if step == 0: units = max(1, units // 2)\n",
    "            model.add(Dense(units, activation='relu'))\n",
    "            step = (step + 1) % step_size\n",
    "    model.add(Dense(1, activation='sigmoid'))  \n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_keras_model():\n",
    "    return KerasClassifier(build_fn=create_model, epochs=100, batch_size=50, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_models(data_x, data_y, file_path, sampler):\n",
    "    csqa = MLExploration(data_x, data_y, file_path)\n",
    "    csqa.explore_model(AdaBoostClassifier, {}, sampler=sampler)\n",
    "    csqa.explore_model(RandomForestClassifier, {}, sampler=sampler)\n",
    "    csqa.explore_model(ExtraTreesClassifier, {}, sampler=sampler)\n",
    "    csqa.explore_model(GradientBoostingClassifier, {}, sampler=sampler)\n",
    "    # csqa.explore_model(GaussianProcessClassifier, {}, sampler=sampler)\n",
    "    # csqa.explore_model(GaussianNB, {}, sampler=sampler)\n",
    "    csqa.explore_model(KNeighborsClassifier, {}, sampler=sampler)\n",
    "    csqa.explore_model(MLPClassifier, {}, sampler=sampler)\n",
    "    csqa.explore_model(SVC, {}, sampler=sampler)\n",
    "    csqa.explore_model(DecisionTreeClassifier, {}, sampler=sampler)\n",
    "    csqa.explore_model(KerasClassifier, {'build_fn':create_model, 'epochs':100, 'batch_size': 50, 'verbose':0}, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('None', \"<class 'scikeras.wrappers.KerasClassifier'>\", \"[('batch_size', 50), ('build_fn', <function create_model at 0x0000021167CEB880>), ('epochs', 100), ('verbose', 0)]\")\n",
      "<class 'scikeras.wrappers.KerasClassifier'>\n",
      "<class 'type'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.src.backend' has no attribute 'floatx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m name \u001b[39m=\u001b[39m row[\u001b[39m0\u001b[39m]\n\u001b[0;32m     28\u001b[0m sampler \u001b[39m=\u001b[39m row[\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 29\u001b[0m try_models(data_x, data_y, cache_file_path, sampler)\n",
      "Cell \u001b[1;32mIn[128], line 13\u001b[0m, in \u001b[0;36mtry_models\u001b[1;34m(data_x, data_y, file_path, sampler)\u001b[0m\n\u001b[0;32m     11\u001b[0m csqa\u001b[39m.\u001b[39mexplore_model(SVC, {}, sampler\u001b[39m=\u001b[39msampler)\n\u001b[0;32m     12\u001b[0m csqa\u001b[39m.\u001b[39mexplore_model(DecisionTreeClassifier, {}, sampler\u001b[39m=\u001b[39msampler)\n\u001b[1;32m---> 13\u001b[0m csqa\u001b[39m.\u001b[39;49mexplore_model(KerasClassifier, {\u001b[39m'\u001b[39;49m\u001b[39mbuild_fn\u001b[39;49m\u001b[39m'\u001b[39;49m:create_model, \u001b[39m'\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m100\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m50\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mverbose\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m0\u001b[39;49m}, sampler\u001b[39m=\u001b[39;49msampler)\n",
      "Cell \u001b[1;32mIn[124], line 41\u001b[0m, in \u001b[0;36mMLExploration.explore_model\u001b[1;34m(self, model, hyperparameters, sampler)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(model_hash))\n\u001b[0;32m     40\u001b[0m scorer \u001b[39m=\u001b[39m ReportAverage()\n\u001b[1;32m---> 41\u001b[0m my_cross_validate(model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhyperparameters), sampler, data_x, data_y, scoring\u001b[39m=\u001b[39;49mscorer\u001b[39m.\u001b[39;49mclassification_report_scorer)\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplored_models\u001b[39m.\u001b[39mloc[index] \u001b[39m=\u001b[39m [\n\u001b[0;32m     44\u001b[0m     MLExploration\u001b[39m.\u001b[39mhash_sampler(sampler),\n\u001b[0;32m     45\u001b[0m     MLExploration\u001b[39m.\u001b[39mhash_model(model_hash), \n\u001b[0;32m     46\u001b[0m     MLExploration\u001b[39m.\u001b[39mhash_hyperparameters(hyperparameters),\n\u001b[0;32m     47\u001b[0m     \u001b[39m*\u001b[39mscorer\u001b[39m.\u001b[39maverage_report()\u001b[39m.\u001b[39mvalues()\n\u001b[0;32m     48\u001b[0m ]\n\u001b[0;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplored_models\u001b[39m.\u001b[39mto_json(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_file_path, orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[123], line 9\u001b[0m, in \u001b[0;36mmy_cross_validate\u001b[1;34m(model, sampler, data_x, data_y, scoring, cv)\u001b[0m\n\u001b[0;32m      6\u001b[0m y_train, y_test \u001b[39m=\u001b[39m data_y\u001b[39m.\u001b[39miloc[train_idx], data_y\u001b[39m.\u001b[39miloc[test_idx]\n\u001b[0;32m      8\u001b[0m \u001b[39mif\u001b[39;00m sampler \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m: X_train, y_train \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[1;32m----> 9\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     11\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     12\u001b[0m results\u001b[39m.\u001b[39mappend(scoring(y_test, y_pred))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py:1491\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m   1489\u001b[0m     sample_weight \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight\n\u001b[0;32m   1490\u001b[0m     sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight, y\u001b[39m=\u001b[39my)\n\u001b[1;32m-> 1491\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, sample_weight\u001b[39m=\u001b[39;49msample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1492\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py:760\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[0;32m    756\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfit__epochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs)\n\u001b[0;32m    757\u001b[0m )\n\u001b[0;32m    758\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m--> 760\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    761\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    762\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    763\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    764\u001b[0m     warm_start\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarm_start,\n\u001b[0;32m    765\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    766\u001b[0m )\n\u001b[0;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py:915\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[39m# Data checks\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mor\u001b[39;00m warm_start) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialized_):\n\u001b[1;32m--> 915\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(X, y)\n\u001b[0;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py:852\u001b[0m, in \u001b[0;36mBaseWrapper._initialize\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    849\u001b[0m feature_meta \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_encoder, \u001b[39m\"\u001b[39m\u001b[39mget_metadata\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mdict\u001b[39m)()\n\u001b[0;32m    850\u001b[0m \u001b[39mvars\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfeature_meta)\n\u001b[1;32m--> 852\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_keras_model()\n\u001b[0;32m    853\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_callbacks()\n\u001b[0;32m    855\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scikeras\\wrappers.py:429\u001b[0m, in \u001b[0;36mBaseWrapper._build_keras_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    427\u001b[0m         model \u001b[39m=\u001b[39m final_build_fn(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbuild_params)\n\u001b[0;32m    428\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 429\u001b[0m     model \u001b[39m=\u001b[39m final_build_fn(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbuild_params)\n\u001b[0;32m    431\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[127], line 5\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(layers, units)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_model\u001b[39m(layers\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, units\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m      6\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(layers):\n\u001b[0;32m      7\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\mixed_precision\\policy.py:360\u001b[0m, in \u001b[0;36mglobal_policy\u001b[1;34m()\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m _global_policy \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[39mif\u001b[39;00m base_layer_utils\u001b[39m.\u001b[39mv2_dtype_behavior_enabled():\n\u001b[1;32m--> 360\u001b[0m         \u001b[39mreturn\u001b[39;00m Policy(backend\u001b[39m.\u001b[39;49mfloatx())\n\u001b[0;32m    361\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m         \u001b[39mreturn\u001b[39;00m Policy(\u001b[39m\"\u001b[39m\u001b[39m_infer\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.src.backend' has no attribute 'floatx'"
     ]
    }
   ],
   "source": [
    "for file_path, cache_file_path in [\n",
    "    ('data/draw/draw-T0.3.jsonl', 'cache/draw/draw-T0.3.json'),\n",
    "    # ('data/draw/draw-T0.5.jsonl', 'cache/draw/draw-T0.5.json'),\n",
    "    # ('data/draw/draw-T0.7.jsonl', 'cache/draw/draw-T0.7.json'),\n",
    "    # ('data/csqa/csqa-T0.3.jsonl', 'cache/csqa/csqa-T0.3.json'),\n",
    "    # ('data/csqa/csqa-T0.5.jsonl', 'cache/csqa/csqa-T0.5.json'),\n",
    "    # ('data/csqa/csqa-T0.7.jsonl', 'cache/csqa/csqa-T0.7.json'),\n",
    "    # ('data/csqa/last_letters-T0.3.jsonl', 'cache/last_letters/last_letters-T0.3.json'),\n",
    "    # ('data/last_letters/last_letters-T0.5.jsonl', 'cache/last_letters/last_letters-T0.5.json'),\n",
    "    # ('data/last_letters/last_letters-T0.7.jsonl', 'cache/last_letters/last_letters-T0.7.json'),\n",
    "]:\n",
    "    data = read_file(file_path)\n",
    "    data_x = data[ATTRIBUTES]\n",
    "    data_y = data[CLASS]\n",
    "\n",
    "    for row in [\n",
    "        ('', None),\n",
    "\n",
    "        ('-ROS', RandomOverSampler(random_state=RANDOM_STATE)),\n",
    "        ('-ADASYN', ADASYN(random_state=RANDOM_STATE)),\n",
    "        ('-SMOTE', SMOTE(random_state=RANDOM_STATE)),\n",
    "\n",
    "        # ('-CNN', CondensedNearestNeighbour(random_state=RANDOM_STATE)),\n",
    "        # ('-ENN', EditedNearestNeighbours()),\n",
    "        ('-RUS', RandomUnderSampler(random_state=RANDOM_STATE))\n",
    "    ]:\n",
    "        name = row[0]\n",
    "        sampler = row[1]\n",
    "        try_models(data_x, data_y, cache_file_path, sampler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
