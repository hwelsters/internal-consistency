{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas\n",
    "from imblearn.pipeline import Pipeline\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import math\n",
    "from typing import Iterable\n",
    "import warnings\n",
    "import tensorflow\n",
    "from sklearn.utils import class_weight\n",
    "import numpy\n",
    "import keras\n",
    "import re\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "\n",
    "tensorflow.get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTES = [\"majority_distance\", \"majority_distance_squared\", \"shannon_entropy\", \"gini_impurity\"]\n",
    "CLASS = 'num_correct'\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLExploration:\n",
    "    def __init__(self, data_x, data_y, scoring, output_file_path):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.scoring = scoring\n",
    "        self.output_file_path = output_file_path\n",
    "        self.explored_models = pandas.DataFrame()\n",
    "        if os.path.exists(output_file_path): self.explored_models = pandas.read_json(output_file_path, lines=True)\n",
    "\n",
    "    def explore_model(self, clf, sampler):\n",
    "        clf_hash = self.__hash_model(clf)\n",
    "        sampler_hash = self.__hash_model(sampler)\n",
    "        \n",
    "        if (\n",
    "            \"clf\" in self.explored_models.columns\n",
    "            and \"sampler\" in self.explored_models.columns\n",
    "            and (self.explored_models[['clf', 'sampler']] == [clf_hash, sampler_hash]).all(axis=1).any()\n",
    "        ):\n",
    "            return\n",
    "\n",
    "        if sampler == None:\n",
    "            model = clf\n",
    "        else:\n",
    "            model = Pipeline([(\"sampler\", sampler), (\"clf\", clf)])\n",
    "        try:\n",
    "                \n",
    "            results = cross_validate(\n",
    "                estimator=model, X=self.data_x, y=self.data_y, scoring=self.scoring\n",
    "            )\n",
    "\n",
    "            row = pandas.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"clf\": clf_hash,\n",
    "                        \"sampler\": sampler_hash,\n",
    "                        **self.__dict_mean(results),\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            self.explored_models = pandas.concat([self.explored_models, row])\n",
    "            self.explored_models.to_json(self.output_file_path, lines=True, orient='records')\n",
    "        except: pass\n",
    "\n",
    "    def __dict_mean(self, obj):\n",
    "        try:\n",
    "            return sum(obj) / len(obj)\n",
    "        except:\n",
    "            return {\n",
    "                key.replace(\"test_\", \"\"): self.__dict_mean(obj[key])\n",
    "                for key in obj.keys()\n",
    "            }\n",
    "\n",
    "    def __hash_model(self, clf):\n",
    "        if type(clf) == KerasClassifier:\n",
    "            cleaned = re.sub(r'\\n\\tmodel\\=.*\\n', '', str(clf), re.DOTALL)\n",
    "            cleaned = re.sub(r'\\n', ',', cleaned, re.DOTALL)\n",
    "            cleaned = re.sub(r'\\t', '', cleaned, re.DOTALL)\n",
    "            return str((cleaned, self.__keras_model_info(clf)))\n",
    "        return str(clf)\n",
    "\n",
    "    def __keras_model_info(self, clf):\n",
    "        return str(\n",
    "            [\n",
    "                (type(layer).__name__, layer.units, layer.activation.__name__)\n",
    "                for layer in clf.model.layers\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, EditedNearestNeighbours, RandomUnderSampler, InstanceHardnessThreshold\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = [\n",
    "        'r2', \n",
    "        'neg_mean_squared_error',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_mean_absolute_error',\n",
    "        'max_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_features, n_layers, units, hidden_activation, output_activation, step_size=5):\n",
    "    model = Sequential()\n",
    "    step = -step_size\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            model.add(Dense(units, input_dim=n_features, activation=hidden_activation))  \n",
    "        else:\n",
    "            if step == 0: units = max(1, units // 2)\n",
    "            model.add(Dense(units, activation=hidden_activation))\n",
    "        step = (step + 1) % step_size\n",
    "    model.add(Dense(1, activation=output_activation))  \n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(loss='crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path, cache_file_path in [\n",
    "    ('data/draw/draw-T0.3.jsonl', 'cache/draw/draw-T0.3.jsonl'),\n",
    "    # ('data/draw/draw-T0.5.jsonl', 'cache/draw/draw-T0.5.json'),\n",
    "    # ('data/draw/draw-T0.7.jsonl', 'cache/draw/draw-T0.7.json'),\n",
    "    # ('data/csqa/csqa-T0.3.jsonl', 'cache/csqa/csqa-T0.3.json'),\n",
    "    # ('data/csqa/csqa-T0.5.jsonl', 'cache/csqa/csqa-T0.5.json'),\n",
    "    # ('data/csqa/csqa-T0.7.jsonl', 'cache/csqa/csqa-T0.7.json'),\n",
    "    # ('data/last_letters/last_letters-T0.3.jsonl', 'cache/last_letters/last_letters-T0.3.json'),\n",
    "    # ('data/last_letters/last_letters-T0.5.jsonl', 'cache/last_letters/last_letters-T0.5.json'),\n",
    "    # ('data/last_letters/last_letters-T0.7.jsonl', 'cache/last_letters/last_letters-T0.7.json'),\n",
    "]:\n",
    "    for sampler in [\n",
    "        None,\n",
    "        RandomOverSampler(random_state=RANDOM_STATE),\n",
    "        ADASYN(random_state=RANDOM_STATE),\n",
    "        SMOTE(random_state=RANDOM_STATE),\n",
    "        # CondensedNearestNeighbour(random_state=RANDOM_STATE),\n",
    "        # EditedNearestNeighbours(),\n",
    "        RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "    ]:\n",
    "        data = pandas.read_json(file_path, lines=True)\n",
    "        data_x = data[ATTRIBUTES]\n",
    "        data_y = data[CLASS]\n",
    "        ml_exploration = MLExploration(\n",
    "            data_x=data_x, data_y=data_y, output_file_path=cache_file_path, scoring=scoring\n",
    "        )\n",
    "        ml_exploration.explore_model(clf=AdaBoostRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=RandomForestRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=ExtraTreesRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=GradientBoostingRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=KNeighborsRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=MLPRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=SVR(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=DecisionTreeRegressor(), sampler=sampler)\n",
    "\n",
    "        class_labels = numpy.unique(data_y)\n",
    "        class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=class_labels, y=data_y)\n",
    "        class_weights = dict(zip(class_labels, class_weights))\n",
    "\n",
    "        # ml_exploration.explore_model(clf=KerasRegressor(model=create_model(len(ATTRIBUTES), 5, 100, 'relu', 'sigmoid', step_size=1), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        # ml_exploration.explore_model(clf=KerasRegressor(model=create_model(len(ATTRIBUTES), 10, 100, 'relu', 'sigmoid', step_size=2), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        # ml_exploration.explore_model(clf=KerasRegressor(model=create_model(len(ATTRIBUTES), 15, 100, 'relu', 'sigmoid', step_size=3), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        # ml_exploration.explore_model(clf=KerasRegressor(model=create_model(len(ATTRIBUTES), 25, 100, 'relu', 'sigmoid', step_size=5), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        # ml_exploration.explore_model(clf=KerasRegressor(model=create_model(len(ATTRIBUTES), 30, 100, 'relu', 'sigmoid', step_size=6), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_exploration.explored_models.to_json('bonkus', lines=True, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
