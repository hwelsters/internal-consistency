{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas\n",
    "from imblearn.pipeline import Pipeline\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import math\n",
    "from typing import Iterable\n",
    "import warnings\n",
    "import tensorflow\n",
    "from sklearn.utils import class_weight\n",
    "import numpy\n",
    "import keras\n",
    "import re\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "\n",
    "tensorflow.get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTES = [\"majority_distance\", \"majority_distance_squared\", \"shannon_entropy\", \"gini_impurity\"]\n",
    "CLASS = 'num_correct'\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLExploration:\n",
    "    def __init__(self, data_x, data_y, scoring, output_file_path):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.scoring = scoring\n",
    "        self.output_file_path = output_file_path\n",
    "        self.explored_models = pandas.DataFrame()\n",
    "        if os.path.exists(output_file_path): self.explored_models = pandas.read_json(output_file_path, lines=True)\n",
    "\n",
    "    def explore_model(self, clf, sampler):\n",
    "        clf_hash = self.__hash_model(clf)\n",
    "        sampler_hash = self.__hash_model(sampler)\n",
    "        \n",
    "        if (\n",
    "            \"clf\" in self.explored_models.columns\n",
    "            and \"sampler\" in self.explored_models.columns\n",
    "            and (self.explored_models[['clf', 'sampler']] == [clf_hash, sampler_hash]).all(axis=1).any()\n",
    "        ):\n",
    "            return\n",
    "\n",
    "        if sampler == None:\n",
    "            model = clf\n",
    "        else:\n",
    "            model = Pipeline([(\"sampler\", sampler), (\"clf\", clf)])\n",
    "        try:\n",
    "                \n",
    "            results = cross_validate(\n",
    "                estimator=model, X=self.data_x, y=self.data_y, scoring=self.scoring\n",
    "            )\n",
    "\n",
    "            row = pandas.DataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        \"clf\": clf_hash,\n",
    "                        \"sampler\": sampler_hash,\n",
    "                        **self.__dict_mean(results),\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            self.explored_models = pandas.concat([self.explored_models, row])\n",
    "            self.explored_models.to_json(self.output_file_path, lines=True, orient='records')\n",
    "        except: pass\n",
    "\n",
    "    def __dict_mean(self, obj):\n",
    "        try:\n",
    "            return sum(obj) / len(obj)\n",
    "        except:\n",
    "            return {\n",
    "                key.replace(\"test_\", \"\"): self.__dict_mean(obj[key])\n",
    "                for key in obj.keys()\n",
    "            }\n",
    "\n",
    "    def __hash_model(self, clf):\n",
    "        if type(clf) == KerasClassifier:\n",
    "            cleaned = re.sub(r'\\n\\tmodel\\=.*\\n', '', str(clf), re.DOTALL)\n",
    "            cleaned = re.sub(r'\\n', ',', cleaned, re.DOTALL)\n",
    "            cleaned = re.sub(r'\\t', '', cleaned, re.DOTALL)\n",
    "            return str((cleaned, self.__keras_model_info(clf)))\n",
    "        return str(clf)\n",
    "\n",
    "    def __keras_model_info(self, clf):\n",
    "        return str(\n",
    "            [\n",
    "                (type(layer).__name__, layer.units, layer.activation.__name__)\n",
    "                for layer in clf.model.layers\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, EditedNearestNeighbours, RandomUnderSampler, InstanceHardnessThreshold\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = [\n",
    "        'r2', \n",
    "        'neg_mean_squared_error',\n",
    "        'neg_median_absolute_error',\n",
    "        'neg_mean_absolute_error',\n",
    "        'max_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_features, n_layers, units, hidden_activation, output_activation, step_size=5):\n",
    "    model = Sequential()\n",
    "    step = -step_size\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            model.add(Dense(units, input_dim=n_features, activation=hidden_activation))  \n",
    "        else:\n",
    "            if step == 0: units = max(1, units // 2)\n",
    "            model.add(Dense(units, activation=hidden_activation))\n",
    "        step = (step + 1) % step_size\n",
    "    model.add(Dense(1, activation=output_activation))  \n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(loss='crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n    X, y, fitted_transformer = fit_resample_one_cached(\n                               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n    return super().fit_resample(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 112, in fit_resample\n    output = self._fit_resample(X, y)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\over_sampling\\_adasyn.py\", line 202, in _fit_resample\n    nns = self.nn_.kneighbors(X_class, return_distance=False)[:, 1:]\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n    raise ValueError(\nValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n    X, y, fitted_transformer = fit_resample_one_cached(\n                               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n    return super().fit_resample(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 112, in fit_resample\n    output = self._fit_resample(X, y)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\over_sampling\\_adasyn.py\", line 202, in _fit_resample\n    nns = self.nn_.kneighbors(X_class, return_distance=False)[:, 1:]\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n    raise ValueError(\nValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m data_y \u001b[39m=\u001b[39m data[CLASS]\n\u001b[0;32m     24\u001b[0m ml_exploration \u001b[39m=\u001b[39m MLExploration(\n\u001b[0;32m     25\u001b[0m     data_x\u001b[39m=\u001b[39mdata_x, data_y\u001b[39m=\u001b[39mdata_y, output_file_path\u001b[39m=\u001b[39mcache_file_path, scoring\u001b[39m=\u001b[39mscoring\n\u001b[0;32m     26\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m ml_exploration\u001b[39m.\u001b[39;49mexplore_model(clf\u001b[39m=\u001b[39;49mAdaBoostRegressor(), sampler\u001b[39m=\u001b[39;49msampler)\n\u001b[0;32m     28\u001b[0m ml_exploration\u001b[39m.\u001b[39mexplore_model(clf\u001b[39m=\u001b[39mRandomForestRegressor(), sampler\u001b[39m=\u001b[39msampler)\n\u001b[0;32m     29\u001b[0m ml_exploration\u001b[39m.\u001b[39mexplore_model(clf\u001b[39m=\u001b[39mExtraTreesRegressor(), sampler\u001b[39m=\u001b[39msampler)\n",
      "Cell \u001b[1;32mIn[37], line 26\u001b[0m, in \u001b[0;36mMLExploration.explore_model\u001b[1;34m(self, clf, sampler)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     model \u001b[39m=\u001b[39m Pipeline([(\u001b[39m\"\u001b[39m\u001b[39msampler\u001b[39m\u001b[39m\"\u001b[39m, sampler), (\u001b[39m\"\u001b[39m\u001b[39mclf\u001b[39m\u001b[39m\"\u001b[39m, clf)])\n\u001b[1;32m---> 26\u001b[0m results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m     27\u001b[0m     estimator\u001b[39m=\u001b[39;49mmodel, X\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_x, y\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_y, scoring\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscoring\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m row \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m     31\u001b[0m     [\n\u001b[0;32m     32\u001b[0m         {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     ]\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplored_models \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mconcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplored_models, row])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n    X, y, fitted_transformer = fit_resample_one_cached(\n                               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n    return super().fit_resample(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 112, in fit_resample\n    output = self._fit_resample(X, y)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\over_sampling\\_adasyn.py\", line 202, in _fit_resample\n    nns = self.nn_.kneighbors(X_class, return_distance=False)[:, 1:]\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n    raise ValueError(\nValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n    X, y, fitted_transformer = fit_resample_one_cached(\n                               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n    return super().fit_resample(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\base.py\", line 112, in fit_resample\n    output = self._fit_resample(X, y)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\imblearn\\over_sampling\\_adasyn.py\", line 202, in _fit_resample\n    nns = self.nn_.kneighbors(X_class, return_distance=False)[:, 1:]\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\nocet\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n    raise ValueError(\nValueError: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6\n"
     ]
    }
   ],
   "source": [
    "for file_path, cache_file_path in [\n",
    "    ('data/draw/draw-T0.3.jsonl', 'cache/draw/draw-T0.3.jsonl'),\n",
    "    # ('data/draw/draw-T0.5.jsonl', 'cache/draw/draw-T0.5.json'),\n",
    "    # ('data/draw/draw-T0.7.jsonl', 'cache/draw/draw-T0.7.json'),\n",
    "    # ('data/csqa/csqa-T0.3.jsonl', 'cache/csqa/csqa-T0.3.json'),\n",
    "    # ('data/csqa/csqa-T0.5.jsonl', 'cache/csqa/csqa-T0.5.json'),\n",
    "    # ('data/csqa/csqa-T0.7.jsonl', 'cache/csqa/csqa-T0.7.json'),\n",
    "    # ('data/last_letters/last_letters-T0.3.jsonl', 'cache/last_letters/last_letters-T0.3.json'),\n",
    "    # ('data/last_letters/last_letters-T0.5.jsonl', 'cache/last_letters/last_letters-T0.5.json'),\n",
    "    # ('data/last_letters/last_letters-T0.7.jsonl', 'cache/last_letters/last_letters-T0.7.json'),\n",
    "]:\n",
    "    for sampler in [\n",
    "        None,\n",
    "        RandomOverSampler(random_state=RANDOM_STATE),\n",
    "        ADASYN(random_state=RANDOM_STATE),\n",
    "        SMOTE(random_state=RANDOM_STATE),\n",
    "        # CondensedNearestNeighbour(random_state=RANDOM_STATE),\n",
    "        # EditedNearestNeighbours(),\n",
    "        RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "    ]:\n",
    "        data = pandas.read_json(file_path, lines=True)\n",
    "        data_x = data[ATTRIBUTES]\n",
    "        data_y = data[CLASS]\n",
    "        ml_exploration = MLExploration(\n",
    "            data_x=data_x, data_y=data_y, output_file_path=cache_file_path, scoring=scoring\n",
    "        )\n",
    "        ml_exploration.explore_model(clf=AdaBoostRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=RandomForestRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=ExtraTreesRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=GradientBoostingRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=KNeighborsRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=MLPRegressor(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=SVR(), sampler=sampler)\n",
    "        ml_exploration.explore_model(clf=DecisionTreeRegressor(), sampler=sampler)\n",
    "\n",
    "        class_labels = numpy.unique(data_y)\n",
    "        class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=class_labels, y=data_y)\n",
    "        class_weights = dict(zip(class_labels, class_weights))\n",
    "\n",
    "        # ml_exploration.explore_model(clf=KerasRegressor(model=create_model(len(ATTRIBUTES), 5, 100, 'relu', 'sigmoid', step_size=1), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        # ml_exploration.explore_model(clf=KerasRegressor(model=create_model(len(ATTRIBUTES), 10, 100, 'relu', 'sigmoid', step_size=2), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        # ml_exploration.explore_model(clf=KerasRegressor(model=create_model(len(ATTRIBUTES), 15, 100, 'relu', 'sigmoid', step_size=3), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        # ml_exploration.explore_model(clf=KerasRegressor(model=create_model(len(ATTRIBUTES), 25, 100, 'relu', 'sigmoid', step_size=5), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())\n",
    "        # ml_exploration.explore_model(clf=KerasRegressor(model=create_model(len(ATTRIBUTES), 30, 100, 'relu', 'sigmoid', step_size=6), verbose=0, epochs=100, batch_size=50), sampler=RandomUnderSampler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_exploration.explored_models.to_json('bonkus', lines=True, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
