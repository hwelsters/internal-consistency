{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "\n",
    "from lab_v2.xlsx_creation import XlsxWorkbook, XlsxSheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRAW_T03 = 'cache/draw/draw-T0.3.json'\n",
    "DRAW_T05 = 'cache/draw/draw-T0.5.json'\n",
    "DRAW_T07 = 'cache/draw/draw-T0.7.json'\n",
    "\n",
    "CSQA_T03 = 'cache/csqa/csqa-T0.3.json'\n",
    "CSQA_T05 = 'cache/csqa/csqa-T0.5.json'\n",
    "CSQA_T07 = 'cache/csqa/csqa-T0.7.json'\n",
    "\n",
    "LAST_LETTERS_T03 = 'cache/last_letters/last_letters-T0.3.json'\n",
    "LAST_LETTERS_T05 = 'cache/last_letters/last_letters-T0.5.json'\n",
    "LAST_LETTERS_T07 = 'cache/last_letters/last_letters-T0.7.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlsx/draw/draw-T0.3.xlsx\n",
      "xlsx/draw/draw-T0.5.xlsx\n",
      "xlsx/draw/draw-T0.7.xlsx\n",
      "xlsx/csqa/csqa-T0.3.xlsx\n",
      "xlsx/csqa/csqa-T0.5.xlsx\n",
      "xlsx/csqa/csqa-T0.7.xlsx\n",
      "xlsx/last_letters/last_letters-T0.3.xlsx\n",
      "xlsx/last_letters/last_letters-T0.5.xlsx\n",
      "xlsx/last_letters/last_letters-T0.7.xlsx\n"
     ]
    }
   ],
   "source": [
    "for cache_file_path in [\n",
    "    'cache/draw/draw-T0.3',\n",
    "    'cache/draw/draw-T0.5',\n",
    "    'cache/draw/draw-T0.7',\n",
    "    'cache/csqa/csqa-T0.3',\n",
    "    'cache/csqa/csqa-T0.5',\n",
    "    'cache/csqa/csqa-T0.7',\n",
    "    'cache/last_letters/last_letters-T0.3',\n",
    "    'cache/last_letters/last_letters-T0.5',\n",
    "    'cache/last_letters/last_letters-T0.7',\n",
    "]:\n",
    "    xlsx_file_path = 'xlsx/' + '/'.join(cache_file_path.split('/')[1:]) + '.xlsx'\n",
    "    print(xlsx_file_path)\n",
    "    data = pandas.read_json(cache_file_path + '.json', lines=True)\n",
    "    data = data.sort_values(by='clf', ascending=False)\n",
    "    data['name'] = data['clf'].apply(lambda row : re.sub(r'Classifier\\(.*', 'Classifier', row, flags=re.DOTALL))\n",
    "    data['layer_count'] = data['clf'].apply(lambda row : row.count('Dense') - 1)\n",
    "    data['name'] = data['name'].apply(lambda row : re.sub(r'\\(|\\)|\\'', '', row, flags=re.DOTALL))\n",
    "    data['name'] = data.apply(lambda row : row['name'] if row['layer_count'] == -1 else 'Tensorflow ' + str(row['layer_count']) + ' layers', axis=1)\n",
    "    \n",
    "    data['R squared'] = data['r2']\n",
    "    data['Median Absolute Error'] = data['neg_median_absolute_error'].apply(lambda row : -row)\n",
    "    data['Mean Absolute Error'] = data['neg_mean_absolute_error'].apply(lambda row : -row)\n",
    "    data['Max Error'] = data['max_error'].apply(lambda row : -row)\n",
    "\n",
    "    COLUMNS = ['name', \n",
    "    'R squared', \n",
    "    'Median Absolute Error', \n",
    "    'Mean Absolute Error',\n",
    "    'Max Error']\n",
    "    none_df = data[data['sampler'] == 'None'][COLUMNS]\n",
    "    undersampled_df = data[data['sampler'] == 'RandomUnderSampler(random_state=42)'][COLUMNS]\n",
    "    oversampled_df = data[data['sampler'] == 'RandomOverSampler(random_state=42)'][COLUMNS]\n",
    "\n",
    "    workbook = XlsxWorkbook(xlsx_file_path)\n",
    "    format = workbook.workbook.add_format()\n",
    "    format.set_text_wrap()\n",
    "\n",
    "    for df, name in [\n",
    "        (none_df, 'None'),\n",
    "        (undersampled_df, 'Random_Undersampling'),\n",
    "        (oversampled_df, 'Random_Oversampling')\n",
    "    ]:\n",
    "        none: XlsxSheet = workbook.add_sheet(name, dataframe=df)\n",
    "        workbook.workbook.get_worksheet_by_name(name).set_column(1, 6, 15)\n",
    "        none_chart = none.add_column_chart('Model Performance', 'H1')\n",
    "        none_chart.set_size({'width': 720, 'height': 400})\n",
    "        index = 0\n",
    "        for _, row in none_df.iterrows():\n",
    "            index += 1\n",
    "            none_chart.add_series({\n",
    "                'name': f'={name}!$B${index + 1}',\n",
    "                'categories': f'={name}!$D$1:$G$1',\n",
    "                'values': f'={name}!$D${index + 1}:$G${index + 1}',\n",
    "            })\n",
    "        none_chart = none.add_column_chart('Model Performance', 'H22')\n",
    "        none_chart.set_size({'width': 720, 'height': 400})\n",
    "        index = 0\n",
    "        for _, row in none_df.iterrows():\n",
    "            index += 1\n",
    "            none_chart.add_series({\n",
    "                'name': f'={name}!$B${index + 1}',\n",
    "                'categories': f'={name}!$C$1:$C$1',\n",
    "                'values': f'={name}!$C${index + 1}:$C${index + 1}',\n",
    "            })\n",
    "    workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
